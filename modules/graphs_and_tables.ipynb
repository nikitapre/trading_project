{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa02f229-1d5f-4980-9aec-6db3ffb6eda6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall_kline_changes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_target_column_mod\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import shap\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.inspection import permutation_importance\n",
    "from datetime import timedelta\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from .all_kline_changes import add_target_column_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd4fccc-7cca-4d06-96a0-84d4a0a3022f",
   "metadata": {},
   "source": [
    "**Расчет метрик F1, Precision, recall, порога вхождения (thrashold) и возвращение модели с оптимальными данными**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc2c483-9650-4cc8-b24a-10329c3e8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_threshold(model, X_train, y_train, X_valid, y_valid, X_test=None, y_test=None):\n",
    "    \"\"\"\n",
    "    Оценивает модель и возвращает результаты в формате для сохранения\n",
    "    \n",
    "    Возвращает словарь в формате:\n",
    "    {\n",
    "        'model': model,  # обученная модель\n",
    "        'metrics': {\n",
    "            'train': {метрики},\n",
    "            'valid': {метрики},\n",
    "            'test': {метрики} (если есть),\n",
    "            'optimal_threshold': float\n",
    "        },\n",
    "        'features': list,  # список фичей\n",
    "        'timestamp': str   # время оценки\n",
    "    }\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # 1. Получаем предсказанные вероятности\n",
    "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "    y_valid_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 2. Создаем диапазон порогов\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    \n",
    "    # 3. Функция для вычисления F1 при разных порогах\n",
    "    def find_best_threshold(y_true, y_proba, thresholds):\n",
    "        f1_scores = []\n",
    "        for t in thresholds:\n",
    "            y_pred = (y_proba >= t).astype(int)\n",
    "            f1_scores.append(f1_score(y_true, y_pred, zero_division=0))\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        return thresholds[best_idx], f1_scores\n",
    "    \n",
    "    # 4. Находим лучшие пороги для train и valid\n",
    "    train_best_threshold, train_f1_scores = find_best_threshold(y_train, y_train_proba, thresholds)\n",
    "    valid_best_threshold, valid_f1_scores = find_best_threshold(y_valid, y_valid_proba, thresholds)\n",
    "    \n",
    "    # 5. Вычисляем средний оптимальный порог\n",
    "    optimal_threshold = np.mean([train_best_threshold, valid_best_threshold])\n",
    "    \n",
    "    # 6. Создаем словари с метриками\n",
    "    train_metrics = {\n",
    "        'thresholds': thresholds,\n",
    "        'f1_scores': train_f1_scores,\n",
    "        'precision': [precision_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'recall': [recall_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'y_proba': y_train_proba,\n",
    "        'max_f1_threshold': train_best_threshold,\n",
    "        'roc_auc': roc_auc_score(y_train, y_train_proba)  # Добавлено ROC AUC\n",
    "    }\n",
    "    \n",
    "    valid_metrics = {\n",
    "        'thresholds': thresholds,\n",
    "        'f1_scores': valid_f1_scores,\n",
    "        'precision': [precision_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'recall': [recall_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'y_proba': y_valid_proba,\n",
    "        'max_f1_threshold': valid_best_threshold,\n",
    "        'roc_auc': roc_auc_score(y_valid, y_valid_proba)  # Добавлено ROC AUC\n",
    "    }\n",
    "    \n",
    "    # 7. Выводим результаты\n",
    "    print(f\"🎯 Лучший порог по F1 (Train): {train_best_threshold:.4f}\")\n",
    "    print(f\"🎯 Лучший порог по F1 (Valid): {valid_best_threshold:.4f}\")\n",
    "    print(f\"✅ Усредненный оптимальный порог: {optimal_threshold:.4f}\")\n",
    "    print(f\"\\n📊 ROC AUC Scores:\")\n",
    "    print(f\"✅ Train ROC AUC: {train_metrics['roc_auc']:.4f}\")\n",
    "    print(f\"✅ Valid ROC AUC: {valid_metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    # 8. Считаем финальные метрики с усредненным порогом\n",
    "    def calculate_final_metrics(y_true, y_proba, threshold, set_name):\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        metrics = {\n",
    "            'F1': f1_score(y_true, y_pred, zero_division=0),\n",
    "            'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "            'ROC_AUC': roc_auc_score(y_true, y_proba)  # Добавлено ROC AUC\n",
    "        }\n",
    "        print(f\"\\n📊 {set_name} set (Threshold = {threshold:.4f}):\")\n",
    "        print(f\"✅ F1: {metrics['F1']:.4f}\")\n",
    "        print(f\"✅ Precision: {metrics['Precision']:.4f}\")\n",
    "        print(f\"✅ Recall: {metrics['Recall']:.4f}\")\n",
    "        print(f\"✅ ROC AUC: {metrics['ROC_AUC']:.4f}\")\n",
    "        return metrics\n",
    "    \n",
    "    train_metrics['final_metrics'] = calculate_final_metrics(y_train, y_train_proba, optimal_threshold, \"Train\")\n",
    "    valid_metrics['final_metrics'] = calculate_final_metrics(y_valid, y_valid_proba, optimal_threshold, \"Valid\")\n",
    "    \n",
    "    results = {\n",
    "        'train': train_metrics,\n",
    "        'valid': valid_metrics,\n",
    "        'optimal_threshold': optimal_threshold\n",
    "    }\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        test_metrics = {\n",
    "            'thresholds': thresholds,\n",
    "            'f1_scores': [f1_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'precision': [precision_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'recall': [recall_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'y_proba': y_test_proba,\n",
    "            'roc_auc': roc_auc_score(y_test, y_test_proba)  # Добавлено ROC AUC\n",
    "        }\n",
    "        test_metrics['final_metrics'] = calculate_final_metrics(\n",
    "            y_test, y_test_proba, optimal_threshold, \"Test\"\n",
    "        )\n",
    "        results['test'] = test_metrics\n",
    "    \n",
    "    # 9. Визуализация (остается без изменений)\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # 1. Кривые для обучающей выборки\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['precision'], label='Precision', color='blue')\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['recall'], label='Recall', color='green')\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='F1', color='red')\n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(train_best_threshold, color='b', linestyle=':', label=f'Train Max F1: {train_best_threshold:.3f}')\n",
    "    plt.title('Train Selection')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 2. Кривые для валидационной выборки\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['precision'], label='Precision', color='blue')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['recall'], label='Recall', color='green')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='F1', color='red')\n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(valid_best_threshold, color='orange', linestyle=':', label=f'Valid Max F1: {valid_best_threshold:.3f}')\n",
    "    plt.title('Test Set')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 3. Сравнение F1-кривых с новым порогом\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='Train F1', color='blue')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='Valid F1', color='orange')\n",
    "    \n",
    "    # Добавлена третья линия для тестовой выборки, если она есть\n",
    "    if X_test is not None and y_test is not None:\n",
    "        plt.plot(test_metrics['thresholds'], test_metrics['f1_scores'], label='Test F1', color='green')\n",
    "    \n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(train_best_threshold, color='b', linestyle=':', alpha=0.5)\n",
    "    plt.axvline(valid_best_threshold, color='orange', linestyle=':', alpha=0.5)\n",
    "    plt.title('F1 Comparison with Optimal Threshold')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 10. Выводим итоговые метрики в таблице (добавляем ROC AUC)\n",
    "    final_table = [\n",
    "        [\"Dataset\", \"Threshold Type\"] + list(train_metrics['final_metrics'].keys()),\n",
    "        [\"Train\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(train_metrics['final_metrics'].values()),\n",
    "        [\"Test\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(valid_metrics['final_metrics'].values())\n",
    "    ]\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        final_table.append(\n",
    "            [\"Test\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(results['test']['final_metrics'].values())\n",
    "        )\n",
    "    \n",
    "    print(\"\\nИтоговые метрики со средним оптимальным порогом:\")\n",
    "    print(tabulate(final_table, headers=\"firstrow\", floatfmt=\".4f\", tablefmt=\"grid\"))\n",
    "\n",
    "     # Формируем итоговый словарь в нужном формате\n",
    "    model_package = {\n",
    "        'model': model,\n",
    "        'metrics': {\n",
    "            'train': train_metrics['final_metrics'],\n",
    "            'valid': valid_metrics['final_metrics'],\n",
    "            'optimal_threshold': optimal_threshold\n",
    "        },\n",
    "        'features': list(X_train.columns),\n",
    "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        model_package['metrics']['test'] = results['test']['final_metrics']\n",
    "    \n",
    "    return model_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d80be6-d251-401c-9a4c-0284423fd8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "661085b7-0f34-4d81-83a8-d8b306347232",
   "metadata": {},
   "source": [
    "Аналогичный расчет с учетом нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5129ae33-6bed-455e-9851-f6b10cbe6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_threshold_mod(model, X_train, y_train, X_valid, y_valid, X_test=None, y_test=None, model_type='sklearn'):\n",
    "    \"\"\"\n",
    "    Оценивает модель (ML или нейросеть) и возвращает результаты с подбором порога\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : object\n",
    "        Обученная модель (sklearn/lightgbm или keras)\n",
    "    model_type : str\n",
    "        Тип модели: 'sklearn' (по умолчанию) или 'keras'\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # 1. Получаем предсказанные вероятности в зависимости от типа модели\n",
    "    if model_type == 'keras':\n",
    "        # Для нейросети\n",
    "        y_train_proba = model.predict(X_train, verbose=0)\n",
    "        y_valid_proba = model.predict(X_valid, verbose=0)\n",
    "        \n",
    "        if len(y_train_proba.shape) > 1 and y_train_proba.shape[1] > 1:\n",
    "            y_train_proba = y_train_proba[:, 1] if y_train_proba.shape[1] == 2 else np.argmax(y_train_proba, axis=1)\n",
    "            y_valid_proba = y_valid_proba[:, 1] if y_valid_proba.shape[1] == 2 else np.argmax(y_valid_proba, axis=1)\n",
    "            \n",
    "        if X_test is not None and y_test is not None:\n",
    "            y_test_proba = model.predict(X_test, verbose=0)\n",
    "            if len(y_test_proba.shape) > 1 and y_test_proba.shape[1] > 1:\n",
    "                y_test_proba = y_test_proba[:, 1] if y_test_proba.shape[1] == 2 else np.argmax(y_test_proba, axis=1)\n",
    "    else:\n",
    "        # Для классических ML-моделей\n",
    "        y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        y_valid_proba = model.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        if X_test is not None and y_test is not None:\n",
    "            y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 2. Создаем диапазон порогов\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    \n",
    "    # 3. Улучшенная функция для нахождения баланса между Precision и Recall\n",
    "    def find_balanced_threshold(y_true, y_proba, thresholds):\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        for t in thresholds:\n",
    "            y_pred = (y_proba >= t).astype(int)\n",
    "            precisions.append(precision_score(y_true, y_pred, zero_division=0))\n",
    "            recalls.append(recall_score(y_true, y_pred, zero_division=0))\n",
    "        \n",
    "        diff = np.abs(np.array(precisions) - np.array(recalls))\n",
    "        exclude = int(len(thresholds) * 0.1)\n",
    "        valid_range = range(exclude, len(thresholds)-exclude)\n",
    "        \n",
    "        if len(valid_range) > 0:\n",
    "            best_idx = valid_range[np.argmin(diff[valid_range])]\n",
    "        else:\n",
    "            best_idx = np.argmin(diff)\n",
    "        \n",
    "        return thresholds[best_idx], precisions, recalls\n",
    "    \n",
    "    # 4. Находим сбалансированные пороги\n",
    "    train_balanced_threshold, train_precisions, train_recalls = find_balanced_threshold(y_train, y_train_proba, thresholds)\n",
    "    valid_balanced_threshold, valid_precisions, valid_recalls = find_balanced_threshold(y_valid, y_valid_proba, thresholds)\n",
    "    optimal_threshold = np.mean([train_balanced_threshold, valid_balanced_threshold])\n",
    "    \n",
    "    # 5. Функция для расчета финальных метрик\n",
    "    def calculate_final_metrics(y_true, y_proba, threshold, set_name):\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        metrics = {\n",
    "            'F1': f1_score(y_true, y_pred, zero_division=0),\n",
    "            'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "            'ROC_AUC': roc_auc_score(y_true, y_proba)\n",
    "        }\n",
    "        print(f\"\\n📊 {set_name} set (Threshold = {threshold:.4f}):\")\n",
    "        print(f\"✅ F1: {metrics['F1']:.4f}\")\n",
    "        print(f\"✅ Precision: {metrics['Precision']:.4f}\")\n",
    "        print(f\"✅ Recall: {metrics['Recall']:.4f}\")\n",
    "        print(f\"✅ ROC AUC: {metrics['ROC_AUC']:.4f}\")\n",
    "        return metrics\n",
    "    \n",
    "    # 6. Вычисляем и выводим метрики\n",
    "    print(f\"🎯 Сбалансированный порог (Train): {train_balanced_threshold:.4f}\")\n",
    "    print(f\"🎯 Сбалансированный порог (Valid): {valid_balanced_threshold:.4f}\")\n",
    "    print(f\"✅ Усредненный оптимальный порог: {optimal_threshold:.4f}\")\n",
    "    \n",
    "    train_metrics = {\n",
    "        'thresholds': thresholds,\n",
    "        'precision': train_precisions,\n",
    "        'recall': train_recalls,\n",
    "        'f1_scores': [f1_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'y_proba': y_train_proba,\n",
    "        'balanced_threshold': train_balanced_threshold,\n",
    "        'final_metrics': calculate_final_metrics(y_train, y_train_proba, optimal_threshold, \"Train\")\n",
    "    }\n",
    "    \n",
    "    valid_metrics = {\n",
    "        'thresholds': thresholds,\n",
    "        'precision': valid_precisions,\n",
    "        'recall': valid_recalls,\n",
    "        'f1_scores': [f1_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'y_proba': y_valid_proba,\n",
    "        'balanced_threshold': valid_balanced_threshold,\n",
    "        'final_metrics': calculate_final_metrics(y_valid, y_valid_proba, optimal_threshold, \"Valid\")\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        'train': train_metrics,\n",
    "        'valid': valid_metrics,\n",
    "        'optimal_threshold': optimal_threshold\n",
    "    }\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        test_balanced_threshold, test_precisions, test_recalls = find_balanced_threshold(y_test, y_test_proba, thresholds)\n",
    "        test_metrics = {\n",
    "            'thresholds': thresholds,\n",
    "            'precision': test_precisions,\n",
    "            'recall': test_recalls,\n",
    "            'f1_scores': [f1_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'y_proba': y_test_proba,\n",
    "            'balanced_threshold': test_balanced_threshold,\n",
    "            'final_metrics': calculate_final_metrics(y_test, y_test_proba, optimal_threshold, \"Test\")\n",
    "        }\n",
    "        results['test'] = test_metrics\n",
    "    \n",
    "    # 9. Визуализация с акцентом на область вокруг оптимального порога\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # 1. Кривые для обучающей выборки\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['precision'], label='Precision', color='blue')\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['recall'], label='Recall', color='green')\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='F1', color='red')\n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(train_balanced_threshold, color='b', linestyle=':', label=f'Train Balanced: {train_balanced_threshold:.3f}')\n",
    "    plt.title('Train Selection')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 2. Кривые для валидационной выборки\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['precision'], label='Precision', color='blue')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['recall'], label='Recall', color='green')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='F1', color='red')\n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(valid_balanced_threshold, color='orange', linestyle=':', label=f'Valid Balanced: {valid_balanced_threshold:.3f}')\n",
    "    plt.title('Validation Set')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 3. Zoom на область вокруг оптимального порога\n",
    "    plt.subplot(1, 3, 3)\n",
    "    zoom_range = 0.2  # +/- 20% от оптимального порога\n",
    "    zoom_min = max(0.01, optimal_threshold - zoom_range)\n",
    "    zoom_max = min(0.99, optimal_threshold + zoom_range)\n",
    "    \n",
    "    mask = (thresholds >= zoom_min) & (thresholds <= zoom_max)\n",
    "    \n",
    "    plt.plot(thresholds[mask], np.array(train_metrics['precision'])[mask], label='Train Precision', color='blue', linestyle='--')\n",
    "    plt.plot(thresholds[mask], np.array(train_metrics['recall'])[mask], label='Train Recall', color='green', linestyle='--')\n",
    "    plt.plot(thresholds[mask], np.array(valid_metrics['precision'])[mask], label='Valid Precision', color='blue')\n",
    "    plt.plot(thresholds[mask], np.array(valid_metrics['recall'])[mask], label='Valid Recall', color='green')\n",
    "    \n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Optimal: {optimal_threshold:.3f}')\n",
    "    plt.title(f'Zoom Around Optimal Threshold ({zoom_min:.2f}-{zoom_max:.2f})')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'metrics': {\n",
    "            'train': train_metrics['final_metrics'],\n",
    "            'valid': valid_metrics['final_metrics'],\n",
    "            'test': results['test']['final_metrics'] if 'test' in results else None,\n",
    "            'optimal_threshold': optimal_threshold\n",
    "        },\n",
    "        'features': list(X_train.columns) if hasattr(X_train, 'columns') else None,\n",
    "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20708ffc-8e3c-4539-947e-e5d865e82e3a",
   "metadata": {},
   "source": [
    "**Точечный график распределения целевой переменной**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f64be1-8dde-4fa0-9eb7-127665e37713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_pairplot(df, features_list):\n",
    "    \"\"\"\n",
    "    Строит pairplot для выбранных признаков с выделением целевой переменной 'target'\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Исходный DataFrame с данными\n",
    "    features_list : list\n",
    "        Список признаков для визуализации (не включая 'target')\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    None (отображает график)\n",
    "    \"\"\"\n",
    "    # Добавляем target к списку признаков\n",
    "    columns_to_plot = features_list + ['target']\n",
    "    \n",
    "    try:\n",
    "        # Удаляем пропуски и выбираем нужные колонки\n",
    "        subset_df = df[columns_to_plot].dropna()\n",
    "        \n",
    "        # Строим pairplot\n",
    "        sns.pairplot(subset_df, hue='target', diag_kind='kde', palette='viridis')\n",
    "        plt.suptitle('Pairplot: selected features vs target', y=1.02)\n",
    "        plt.show()\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"Ошибка: в DataFrame отсутствует колонка {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка: {e}\")\n",
    "\n",
    "# Пример использования:\n",
    "# plot_feature_pairplot(df, ['senkou_span_a_norm', 'senkou_span_b_norm', 'breakout_in_5', 'atr_14_norm%', 'EFI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dafc2-5c7f-4242-955e-7faa4df7b959",
   "metadata": {},
   "source": [
    "**Корреляционная матрица**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45db092a-8ec3-43f5-8eca-21c238ce746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation_matrix(df, drop_columns=['Data', 'High', 'Low', 'Close', 'Open', 'Volume']):\n",
    "    \"\"\"\n",
    "    Улучшенная версия с лучшей читаемостью для большого числа признаков.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Удаляем ненужные колонки\n",
    "        data = df.drop(drop_columns, axis=1, errors='ignore')\n",
    "        \n",
    "        # Рассчитываем корреляционную матрицу\n",
    "        corr_matrix = data.corr()\n",
    "        num_features = len(corr_matrix)\n",
    "        \n",
    "        # Динамические настройки в зависимости от количества признаков\n",
    "        if num_features <= 15:\n",
    "            figsize = (10, 8)\n",
    "            font_scale = 1.2\n",
    "            annot = True\n",
    "            label_size = 10\n",
    "        elif num_features <= 30:\n",
    "            figsize = (16, 14)\n",
    "            font_scale = 1.0\n",
    "            annot = False\n",
    "            label_size = 9\n",
    "        else:  # Для 50+ признаков\n",
    "            figsize = (20, 18)\n",
    "            font_scale = 0.8\n",
    "            annot = False\n",
    "            label_size = 8\n",
    "            # Для очень большого числа признаков можно уменьшить плотность меток\n",
    "            plt.rcParams['xtick.major.pad'] = 0.5\n",
    "            plt.rcParams['ytick.major.pad'] = 0.5\n",
    "        \n",
    "        # Настройка стиля\n",
    "        sns.set(font_scale=font_scale)\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Построение тепловой карты с улучшенными настройками\n",
    "        heatmap = sns.heatmap(\n",
    "            corr_matrix,\n",
    "            cmap='coolwarm',\n",
    "            annot=annot,\n",
    "            fmt=\".2f\",\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.7},\n",
    "            mask=np.triu(np.ones_like(corr_matrix, dtype=bool)),\n",
    "            annot_kws={\"size\": 8} if annot else None\n",
    "        )\n",
    "        \n",
    "        # Настройка подписей осей\n",
    "        heatmap.set_xticklabels(\n",
    "            heatmap.get_xticklabels(),\n",
    "            rotation=45,\n",
    "            ha='right',\n",
    "            fontsize=label_size\n",
    "        )\n",
    "        heatmap.set_yticklabels(\n",
    "            heatmap.get_yticklabels(),\n",
    "            rotation=0,\n",
    "            fontsize=label_size\n",
    "        )\n",
    "        \n",
    "        plt.title(f'Корреляционная матрица ({num_features} признаков)', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при построении графика: {str(e)}\")\n",
    "\n",
    "# Пример использования:\n",
    "# plot_correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048e95a-d19e-4ce1-8872-de7af6f388bb",
   "metadata": {},
   "source": [
    "**Корреляция топ 20**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61fedce2-17d0-4b6d-a3c5-c27630a47bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlated_pairs(df, top_n=20):\n",
    "    # Вычисляем матрицу корреляций\n",
    "    corr_matrix = df.corr().abs()  # Берем модуль корреляции\n",
    "    \n",
    "    # Создаем список всех уникальных пар (без дублирования A:B и B:A)\n",
    "    pairs = []\n",
    "    cols = corr_matrix.columns\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i + 1, len(cols)):  # Исключаем диагональ и зеркальные пары\n",
    "            pairs.append((cols[i], cols[j], corr_matrix.iloc[i, j]))\n",
    "    \n",
    "    # Сортируем пары по убыванию корреляции\n",
    "    pairs_sorted = sorted(pairs, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Выводим топ-N пар\n",
    "    print(f\"Топ-{top_n} пар по корреляции:\")\n",
    "    for pair in pairs_sorted[:top_n]:\n",
    "        print(f\"{pair[0]} : {pair[1]} : {pair[2]:.4f}\")\n",
    "\n",
    "# Пример использования:\n",
    "# get_top_correlated_pairs(df, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b8e62-7078-4022-a845-b39e7fe4ec2f",
   "metadata": {},
   "source": [
    "**SHAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60e8a525-9255-464c-abb5-483ed130da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_shap(X_train, model, sample_size=2000, top_n=20, n_jobs = -1):\n",
    "    \"\"\"\n",
    "    Оборачивает расчет SHAP-важности и визуализации признаков\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Датафрейм признаков\n",
    "    model : sklearn/xgboost модель\n",
    "        Обученная модель (RandomForest, LogisticRegression, XGB и др.)\n",
    "    sample_size : int\n",
    "        Размер случайной подвыборки\n",
    "    top_n : int\n",
    "        Кол-во признаков для отображения\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_start_time = time.time()\n",
    "        model_type = type(model).__name__\n",
    "        \n",
    "        print(f\"ℹ️ Model type: {model_type}\")\n",
    "        print(f\"ℹ️ Number of classes: {getattr(model, 'n_classes_', 'unknown')}\")\n",
    "        \n",
    "        # 1. Инициализация Explainer\n",
    "        print(\"🔄 Initializing SHAP explainer...\")\n",
    "        explainer_start = time.time()\n",
    "        if model_type in ['RandomForestClassifier', 'RandomForestRegressor', \n",
    "                          'XGBClassifier', 'XGBRegressor', \n",
    "                          'LGBMClassifier', 'LGBMRegressor']:\n",
    "            explainer = shap.TreeExplainer(model, feature_perturbation=\"tree_path_dependent\")\n",
    "        elif model_type in ['LogisticRegression', 'LinearRegression']:\n",
    "            explainer = shap.LinearExplainer(model, X_train)\n",
    "        else:\n",
    "            explainer = shap.Explainer(model, X_train)\n",
    "        explainer_time = time.time() - explainer_start\n",
    "        print(f\"✅ SHAP explainer initialized in {timedelta(seconds=explainer_time)}\")\n",
    "        \n",
    "        # 2. Подвыборка\n",
    "        sample_size = min(sample_size, len(X_train))\n",
    "        sample_idx = np.random.choice(X_train.index, size=sample_size, replace=False)\n",
    "        X_sample = X_train.loc[sample_idx]\n",
    "\n",
    "        print(f\"\\n🔄 Calculating SHAP values for {sample_size} samples...\")\n",
    "        shap_start = time.time()\n",
    "\n",
    "        # Параллельная обработка\n",
    "        n_jobs = n_jobs\n",
    "        n_chunks = 4 * (os.cpu_count() or 1)\n",
    "\n",
    "        def calc_chunk(chunk):\n",
    "            return explainer.shap_values(chunk, approximate=True, check_additivity=False)\n",
    "\n",
    "        chunks = np.array_split(X_sample, n_chunks)\n",
    "        results = Parallel(n_jobs=n_jobs)(delayed(calc_chunk)(chunk) for chunk in chunks)\n",
    "\n",
    "        # Объединение результатов\n",
    "        if isinstance(results[0], list):\n",
    "            shap_values = [np.concatenate([r[i] for r in results]) for i in range(len(results[0]))]\n",
    "        else:\n",
    "            shap_values = np.concatenate(results)\n",
    "\n",
    "        shap_time = time.time() - shap_start\n",
    "        print(f\"✅ SHAP values calculated in {timedelta(seconds=shap_time)}\")\n",
    "        print(f\"⏱ Average time per sample: {shap_time/sample_size:.4f} seconds\")\n",
    "\n",
    "        # 3. Обработка SHAP\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[1] if len(shap_values) == 2 else np.mean(shap_values, axis=0)\n",
    "        elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
    "            shap_values = shap_values[:, :, 1]\n",
    "\n",
    "        print(f\"ℹ️ Processed SHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "        # 4. Анализ важности\n",
    "        print(\"\\n🔄 Calculating feature importance...\")\n",
    "        analysis_start = time.time()\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'SHAP_Importance': np.abs(shap_values).mean(axis=0),\n",
    "            'Direction': np.where(np.mean(shap_values, axis=0) > 0, 'Positive', 'Negative')\n",
    "        })\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance_df['Model_Importance'] = model.feature_importances_\n",
    "            importance_df['Model_%'] = 100 * importance_df['Model_Importance'] / importance_df['Model_Importance'].max()\n",
    "\n",
    "        importance_df['SHAP_%'] = 100 * importance_df['SHAP_Importance'] / importance_df['SHAP_Importance'].max()\n",
    "        importance_df = importance_df.sort_values('SHAP_%', ascending=False)\n",
    "        importance_df['Rank'] = range(1, len(importance_df) + 1)\n",
    "        importance_df['Cumulative_SHAP_%'] = importance_df['SHAP_%'].cumsum()\n",
    "        analysis_time = time.time() - analysis_start\n",
    "        print(f\"✅ Feature analysis completed in {timedelta(seconds=analysis_time)}\")\n",
    "\n",
    "        # 5. Таблица\n",
    "        print(\"\\n🔍 Top Features by SHAP Importance:\")\n",
    "        display_cols = ['Rank', 'Feature', 'SHAP_%', 'Direction']\n",
    "        if 'Model_%' in importance_df.columns:\n",
    "            display_cols.append('Model_%')\n",
    "        print(importance_df.head(top_n)[display_cols].to_markdown(index=False, floatfmt=\".1f\"))\n",
    "\n",
    "        print(\"\\n📊 Key Metrics:\")\n",
    "        print(f\"• Top-5 features explain: {importance_df['Cumulative_SHAP_%'].iloc[4]:.1f}%\")\n",
    "        pos_count = (importance_df['Direction'] == 'Positive').sum()\n",
    "        neg_count = (importance_df['Direction'] == 'Negative').sum()\n",
    "        print(f\"• Positive/Negative: {pos_count}/{neg_count}\")\n",
    "\n",
    "        # 6. Простая визуализация\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        colors = importance_df['Direction'].head(top_n).map({'Positive': 'tomato', 'Negative': 'dodgerblue'})\n",
    "        plt.barh(importance_df['Feature'].head(top_n)[::-1], \n",
    "                 importance_df['SHAP_%'].head(top_n)[::-1],\n",
    "                 color=colors[::-1])\n",
    "        plt.title(f'Top {top_n} Features by SHAP')\n",
    "        plt.xlabel('Relative SHAP Importance (%)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 7. Общее время\n",
    "        total_time = time.time() - total_start_time\n",
    "        print(f\"\\n⏱ Total execution time: {timedelta(seconds=total_time)}\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"Time breakdown:\")\n",
    "        print(f\"- Explainer init: {timedelta(seconds=explainer_time)}\")\n",
    "        print(f\"- SHAP values: {timedelta(seconds=shap_time)} ({shap_time/total_time*100:.1f}%)\")\n",
    "        print(f\"- Analysis: {timedelta(seconds=analysis_time)} ({analysis_time/total_time*100:.1f}%)\")\n",
    "\n",
    "        return importance_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {str(e)}\")\n",
    "        if 'shap_values' in locals():\n",
    "            print(f\"SHAP values type: {type(shap_values)}\")\n",
    "            if hasattr(shap_values, 'shape'):\n",
    "                print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "        print(f\"X_train shape: {X_train.shape if X_train is not None else 'N/A'}\")\n",
    "        if hasattr(model, 'n_features_in_'):\n",
    "            print(f\"Model features: {model.n_features_in_}\")\n",
    "        return None\n",
    "# Пример использования:\n",
    "# explain_model_shap(X_train, logreg_model)\n",
    "# explain_model_shap(X_train, rf_model, sample_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48525a07-ac73-4a84-9020-140d2e470046",
   "metadata": {},
   "source": [
    "**Permutation importance (расчет важности признаков при перестановки)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b969d1e1-109a-44c8-bda1-4d4448005940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_permutation(X, y, model, scoring='f1', n_repeats=5, top_n=20, random_state=3):\n",
    "    \"\"\"\n",
    "    Оценивает важность признаков с помощью Permutation Importance.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Признаки (X_train или X_valid)\n",
    "    y : pd.Series\n",
    "        Целевая переменная\n",
    "    model : обученная модель\n",
    "        RandomForest, LogisticRegression, XGBoost и т.д.\n",
    "    scoring : str\n",
    "        Метрика (например, 'f1', 'accuracy', 'roc_auc')\n",
    "    n_repeats : int\n",
    "        Количество повторов для случайности\n",
    "    top_n : int\n",
    "        Кол-во признаков для отображения\n",
    "    random_state : int\n",
    "        Случайное зерно для воспроизводимости\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pd.DataFrame — таблица важности признаков\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ℹ️ Model type: {type(model).__name__}\")\n",
    "        print(f\"ℹ️ Scoring metric: {scoring}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Оптимальное количество потоков\n",
    "        n_jobs = os.cpu_count() - 1 if os.cpu_count() else 1\n",
    "\n",
    "        print(\"🔄 Calculating permutation importance...\")\n",
    "        result = permutation_importance(\n",
    "            model, X, y,\n",
    "            scoring=scoring,\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"✅ Completed in {timedelta(seconds=elapsed)}\")\n",
    "\n",
    "        # Формируем датафрейм\n",
    "        importances_df = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Mean Importance': result.importances_mean,\n",
    "            'Std': result.importances_std\n",
    "        })\n",
    "        importances_df['Significant'] = importances_df['Mean Importance'] - 2 * importances_df['Std'] > 0\n",
    "        importances_df = importances_df.sort_values(by='Mean Importance', ascending=False).reset_index(drop=True)\n",
    "        importances_df['Rank'] = importances_df.index + 1\n",
    "\n",
    "        print(\"\\n🔍 Top Features by Permutation Importance:\")\n",
    "        display_cols = ['Rank', 'Feature', 'Mean Importance', 'Std', 'Significant']\n",
    "        print(importances_df.head(top_n)[display_cols].to_markdown(index=False, floatfmt=\".3f\"))\n",
    "\n",
    "        # Простая визуализация\n",
    "        top_features = importances_df.head(top_n)\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        bars = plt.barh(top_features['Feature'][::-1], top_features['Mean Importance'][::-1],\n",
    "                        xerr=top_features['Std'][::-1], color='mediumseagreen')\n",
    "        plt.xlabel(\"Mean Importance\")\n",
    "        plt.title(f\"Top {top_n} Features by Permutation Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return importances_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during permutation importance: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b3f09c-bee4-41fe-87a0-ee404c2d85ae",
   "metadata": {},
   "source": [
    "**RFECV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e8b32e6-de77-4402-b9c3-4826dd4f123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rfecv_results(X_train, y_train, estimator, \n",
    "                      scoring='f1', step=1, n_splits=3, \n",
    "                      n_jobs=-1, verbose=0):\n",
    "    \"\"\"\n",
    "    Выполняет отбор признаков с помощью RFECV и показывает результаты:\n",
    "    - список отобранных признаков\n",
    "    - график зависимости качества от количества признаков\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame или array-like\n",
    "        Матрица признаков для обучения\n",
    "    y_train : pd.Series или array-like\n",
    "        Вектор целевой переменной\n",
    "    estimator : объект модели\n",
    "        Уже инициализированная модель (например, RandomForestClassifier())\n",
    "    scoring : str, default='f1'\n",
    "        Метрика для оценки\n",
    "    step : int, default=1\n",
    "        Количество удаляемых признаков на каждой итерации\n",
    "    n_splits : int, default=3\n",
    "        Количество фолдов для TimeSeriesSplit\n",
    "    n_jobs : int, default=-1\n",
    "        Количество ядер для параллельных вычислений\n",
    "    verbose : int, default=0\n",
    "        Уровень детализации вывода\n",
    "    \"\"\"\n",
    "    \n",
    "    # TimeSeries split\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    # RFECV с переданной моделью и TSCV\n",
    "    rfecv_selector = RFECV(\n",
    "        estimator=estimator,\n",
    "        step=step,\n",
    "        cv=tscv,\n",
    "        scoring=scoring,\n",
    "        verbose=verbose,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    \n",
    "    # Копируем данные, чтобы избежать предупреждений\n",
    "    X_rfecv = X_train.copy() if isinstance(X_train, pd.DataFrame) else X_train\n",
    "    y_rfecv = y_train.copy()\n",
    "    \n",
    "    # Выполняем отбор признаков\n",
    "    rfecv_selector.fit(X_rfecv, y_rfecv)\n",
    "    \n",
    "    # Получаем имена отобранных признаков\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        rfecv_features = X_train.columns[rfecv_selector.support_].tolist()\n",
    "    else:\n",
    "        rfecv_features = [f\"feature_{i}\" for i, selected in enumerate(rfecv_selector.support_) if selected]\n",
    "    \n",
    "    # Выводим результаты\n",
    "    print(\"\\n✅ Признаки, отобранные RFECV:\")\n",
    "    print(rfecv_features)\n",
    "    \n",
    "    # Строим график\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(rfecv_selector.cv_results_['mean_test_score']) + 1),\n",
    "             rfecv_selector.cv_results_['mean_test_score'])\n",
    "    plt.xlabel(\"Количество признаков\")\n",
    "    plt.ylabel(f\"{scoring} score\")\n",
    "    plt.title(f\"Качество модели ({estimator.__class__.__name__}) в зависимости от числа признаков (RFECV)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8dda2-0527-400d-8f8d-ced1e8c7cf8a",
   "metadata": {},
   "source": [
    "**Boruta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c84285-9dad-4e4d-aaa3-04406f72946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_boruta(\n",
    "    X_train, \n",
    "    X_valid, \n",
    "    y_train, \n",
    "    y_valid, \n",
    "    model, \n",
    "    max_iter=100, \n",
    "    n_splits=3, \n",
    "    random_state=3,\n",
    "    perc=100,\n",
    "    alpha=0.05,\n",
    "    two_step=True,\n",
    "    n_estimators='auto',\n",
    "    verbose=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Выполняет отбор признаков с помощью Boruta и TimeSeriesSplit.\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Признаки обучающей выборки\n",
    "    X_valid : pd.DataFrame\n",
    "        Признаки валидационной выборки (не используется, включен для единообразия)\n",
    "    y_train : pd.Series\n",
    "        Целевая переменная обучающей выборки\n",
    "    y_valid : pd.Series\n",
    "        Целевая переменная валидационной выборки (не используется)\n",
    "    model : объект\n",
    "        Обучаемая модель (RandomForest, XGBoost, LogisticRegression и др.)\n",
    "    max_iter : int, default=100\n",
    "        Максимальное количество итераций Boruta (чем больше, тем тщательнее отбор,\n",
    "        но дольше выполнение)\n",
    "    n_splits : int, default=3\n",
    "        Количество разбиений в TimeSeriesSplit (для временных рядов)\n",
    "    random_state : int, default=3\n",
    "        Зерно генератора случайных чисел для воспроизводимости\n",
    "    perc : int, default=100\n",
    "        Процент отбора признаков для сравнения с шумом (меньшие значения делают\n",
    "        отбор более консервативным)\n",
    "    alpha : float, default=0.05\n",
    "        Уровень значимости для отбраковки гипотез (меньше = строже отбор)\n",
    "    two_step : bool, default=True\n",
    "        Использовать двухэтапную процедуру (True рекомендуется для больших наборов данных)\n",
    "    n_estimators : int или 'auto', default='auto'\n",
    "        Количество деревьев в ансамбле (если 'auto', берется из модели)\n",
    "    verbose : int, default=0\n",
    "        Уровень детализации вывода (0 - нет вывода, 1 - базовый, 2 - подробный)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ℹ️ Model type: {type(model).__name__}\")\n",
    "        print(f\"ℹ️ Boruta params: max_iter={max_iter}, perc={perc}, alpha={alpha}\")\n",
    "        print(f\"ℹ️ TimeSeriesSplit n_splits: {n_splits}\")\n",
    "\n",
    "        X_df = X_train.copy()\n",
    "        X_array, y_array = X_df.values, y_train.values\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "        boruta = BorutaPy(\n",
    "            estimator=model,\n",
    "            n_estimators=n_estimators,\n",
    "            verbose=verbose,\n",
    "            random_state=random_state,\n",
    "            max_iter=max_iter,\n",
    "            perc=perc,\n",
    "            alpha=alpha,\n",
    "            two_step=two_step\n",
    "        )\n",
    "\n",
    "        print(\"🔄 Running Boruta feature selection on time series splits...\")\n",
    "\n",
    "        support_masks = []\n",
    "        for i, (train_idx, test_idx) in enumerate(tscv.split(X_array)):\n",
    "            print(f\"  • Fold {i+1}/{n_splits} — Train size: {len(train_idx)}, Test size: {len(test_idx)}\")\n",
    "            X_fold_train, y_fold_train = X_array[train_idx], y_array[train_idx]\n",
    "            boruta.fit(X_fold_train, y_fold_train)\n",
    "            support_masks.append(boruta.support_.copy())\n",
    "\n",
    "        # Пересечение масок по всем фолдам\n",
    "        final_support = np.all(support_masks, axis=0)\n",
    "        selected_features = X_df.columns[final_support].tolist()\n",
    "\n",
    "        print(f\"\\n✅ Итоговые отобранные признаки ({len(selected_features)}):\")\n",
    "        for i, feat in enumerate(selected_features, 1):\n",
    "            print(f\"{i:>2}. {feat}\")\n",
    "\n",
    "        return selected_features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка при выполнении Boruta: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcddf16a-3c53-429e-8b0c-c3e7522d8ff2",
   "metadata": {},
   "source": [
    "**Mutual Information (взаимная информация)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f9d2c64-90cd-40ab-81d0-d6ab45b5cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_mutual_info(X_train, y_train, top_n=20, random_state=3):\n",
    "    \"\"\"\n",
    "    Расчёт важности признаков на основе Mutual Information.\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Обучающая выборка признаков\n",
    "    y_train : pd.Series\n",
    "        Целевая переменная\n",
    "    top_n : int\n",
    "        Количество признаков для отображения\n",
    "    random_state : int\n",
    "        Зерно генератора случайных чисел для MI-оценки\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(f\"ℹ️ Calculating Mutual Information for {X_train.shape[1]} features...\")\n",
    "\n",
    "        # 1. Расчёт MI\n",
    "        mi_scores = mutual_info_classif(X_train, y_train, random_state=random_state)\n",
    "        mi_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'MI_Score': mi_scores\n",
    "        }).sort_values('MI_Score', ascending=False)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"✅ MI calculation completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # 2. Таблица топ-N\n",
    "        print(f\"\\n🔍 Top {top_n} Features by Mutual Information:\")\n",
    "        print(mi_df.head(top_n).to_markdown(index=False, floatfmt=\".4f\"))\n",
    "\n",
    "        # 3. Визуализация\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        plt.barh(mi_df['Feature'].head(top_n)[::-1], \n",
    "                 mi_df['MI_Score'].head(top_n)[::-1], \n",
    "                 color='skyblue')\n",
    "        plt.xlabel('Mutual Information Score')\n",
    "        plt.title(f'Top {top_n} Features by Mutual Information')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка при расчёте Mutual Information: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40c400-0e00-4347-bac5-b25441123017",
   "metadata": {},
   "source": [
    "**Granger Causality (причинность по Грейнджеру)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d06b104-c1f2-4424-a1a7-8a39ab764afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_granger(X_train, y_train, target_name='target', max_lag=5, top_n=20):\n",
    "    \"\"\"\n",
    "    Анализ Granger Causality между признаками и целевой переменной.\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Признаки обучающей выборки\n",
    "    y_train : pd.Series\n",
    "        Целевая переменная\n",
    "    target_name : str\n",
    "        Название целевой переменной (для подписи)\n",
    "    max_lag : int\n",
    "        Максимальное количество лагов для теста Грейнджера\n",
    "    top_n : int\n",
    "        Количество признаков для отображения\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(f\"ℹ️ Calculating Granger causality for {X_train.shape[1]} features...\")\n",
    "\n",
    "        def check_granger_causality(feature_series, target_series, max_lag=5):\n",
    "            data = pd.DataFrame({\n",
    "                'target': target_series,\n",
    "                'feature': feature_series\n",
    "            }).dropna()\n",
    "            try:\n",
    "                test_result = grangercausalitytests(data[['target', 'feature']], maxlag=max_lag, verbose=False)\n",
    "                p_values = [test_result[i+1][0]['ssr_chi2test'][1] for i in range(max_lag)]\n",
    "                return np.min(p_values)\n",
    "            except:\n",
    "                return np.nan  # В случае ошибки вернуть NaN\n",
    "\n",
    "        granger_results = {\n",
    "            feature: check_granger_causality(X_train[feature], y_train)\n",
    "            for feature in X_train.columns\n",
    "        }\n",
    "\n",
    "        granger_df = pd.DataFrame({\n",
    "            'Feature': list(granger_results.keys()),\n",
    "            'Granger_p_value': list(granger_results.values())\n",
    "        }).dropna().sort_values('Granger_p_value')\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"✅ Granger analysis completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # Вывод таблицы\n",
    "        print(f\"\\n🔍 Top {top_n} Features by Granger Causality (lowest p-values):\")\n",
    "        print(granger_df.head(top_n).to_markdown(index=False, floatfmt=\".4e\"))\n",
    "\n",
    "        # Визуализация\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        plt.barh(granger_df['Feature'].head(top_n)[::-1],\n",
    "                 -np.log10(granger_df['Granger_p_value'].head(top_n)[::-1]),\n",
    "                 color='salmon')\n",
    "        plt.xlabel(r'$-\\log_{10}$(p-value)')\n",
    "        plt.title(f'Top {top_n} Features by Granger Causality vs \"{target_name}\"')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка при анализе Granger Causality: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d6b46-7930-4b3c-aab4-75ae4b51577d",
   "metadata": {},
   "source": [
    "**Зависимость F1 модели от количества деревьев**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8cd29fb-819a-409d-a5e4-fd732306658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_n(n, base_model, cv_splits, X_train_arr, y_train_arr):\n",
    "    \"\"\"Глобальная функция для оценки модели с заданным n_estimators.\"\"\"\n",
    "    model = clone(base_model).set_params(\n",
    "        n_estimators=n,\n",
    "        warm_start=True,  # Инкрементальное обучение\n",
    "        verbose=0\n",
    "    )\n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv_splits:\n",
    "        X_train_fold = X_train_arr[train_idx]\n",
    "        X_test_fold = X_train_arr[test_idx]\n",
    "        y_train_fold = y_train_arr[train_idx]\n",
    "        y_test_fold = y_train_arr[test_idx]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        pred = model.predict(X_test_fold)\n",
    "        scores.append(f1_score(y_test_fold, pred))\n",
    "    return np.mean(scores)\n",
    "\n",
    "def plot_f1_vs_n_estimators(X_train, y_train, base_model, \n",
    "                          n_estimators_range=(100, 1000), step=50, \n",
    "                          n_splits=3, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Оптимизированная версия с использованием joblib.Parallel.\n",
    "    \"\"\"\n",
    "    # Проверка входных данных\n",
    "    if not hasattr(base_model, 'fit') or not hasattr(base_model, 'predict'):\n",
    "        raise ValueError(\"base_model должен быть моделью scikit-learn с методами fit и predict\")\n",
    "    \n",
    "    n_estimators_values = np.arange(\n",
    "        n_estimators_range[0], \n",
    "        n_estimators_range[1] + 1, \n",
    "        step\n",
    "    )\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    cv_splits = list(tscv.split(X_train))\n",
    "    \n",
    "    # Конвертация в numpy array для ускорения\n",
    "    X_train_arr = X_train.values if hasattr(X_train, 'iloc') else X_train\n",
    "    y_train_arr = y_train.values if hasattr(y_train, 'iloc') else y_train\n",
    "    \n",
    "    # Игнорирование предупреждений\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        print(f\"⏳ Анализ {len(n_estimators_values)} значений n_estimators...\")\n",
    "        \n",
    "        # Параллельные вычисления через joblib\n",
    "        f1_scores = Parallel(n_jobs=n_jobs, backend=\"loky\")(\n",
    "            delayed(evaluate_n)(\n",
    "                n, base_model, cv_splits, X_train_arr, y_train_arr\n",
    "            ) for n in tqdm(n_estimators_values, desc=\"n_estimators\")\n",
    "        )\n",
    "        \n",
    "        # Фильтрация NaN результатов\n",
    "        valid_mask = ~np.isnan(f1_scores)\n",
    "        n_estimators_values = n_estimators_values[valid_mask]\n",
    "        f1_scores = np.array(f1_scores)[valid_mask]\n",
    "        \n",
    "        if not len(f1_scores):\n",
    "            print(\"⚠️ Все вычисления завершились с ошибкой!\")\n",
    "            return\n",
    "        \n",
    "        # Построение графика\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(n_estimators_values, f1_scores, 'b-o', alpha=0.7)\n",
    "        plt.title(f'Зависимость F1 от n_estimators ({base_model.__class__.__name__})')\n",
    "        plt.xlabel('n_estimators')\n",
    "        plt.ylabel('F1-score (CV среднее)')\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        \n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        plt.scatter(\n",
    "            n_estimators_values[best_idx], f1_scores[best_idx],\n",
    "            color='red', s=150, zorder=5,\n",
    "            label=f'Лучшее: {f1_scores[best_idx]:.4f} (n={n_estimators_values[best_idx]})'\n",
    "        )\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"✅ Оптимальное количество деревьев: {n_estimators_values[best_idx]} с F1={f1_scores[best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e3bec-a32f-4f4b-8282-606158788da6",
   "metadata": {},
   "source": [
    "**Распределение целевой переменной внутри выборок**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191b7a75-79b0-46ef-bfbd-3e580f677b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_class_balance(y, y_train, y_valid, y_test):\n",
    "    # Собираем данные в таблицу\n",
    "    balance_df = pd.DataFrame({\n",
    "        'Весь датасет': y.value_counts(normalize=True).round(3),\n",
    "        'Обучающая': y_train.value_counts(normalize=True).round(3),\n",
    "        'Валидационная': y_valid.value_counts(normalize=True).round(3),\n",
    "        'Тестовая': y_test.value_counts(normalize=True).round(3)\n",
    "    }).fillna(0)  # на случай отсутствующих классов\n",
    "    \n",
    "    # Выводим таблицу в стиле \"plain\"\n",
    "    print(\"📊 Баланс классов (доли):\")\n",
    "    print(\n",
    "        balance_df.to_markdown(\n",
    "            tablefmt=\"simple\",  # Чистый формат без лишних линий\n",
    "            stralign=\"center\",  # Выравнивание по центру\n",
    "            floatfmt=\".3f\"       # Формат чисел\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    balance_df.plot(kind='bar', width=0.8, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "    plt.title('Распределение классов по выборкам', pad=20)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel('Доля класса')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.legend(framealpha=0.9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132a029-cdc5-494d-9094-455317c04389",
   "metadata": {},
   "source": [
    "**Подбор оптимального соотношения риск прибыль**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "585506cf-1d9d-4b64-b03d-87c5b5665bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_parameters(df, X, train_index, valid_index, \n",
    "                       target_candles=20,\n",
    "    \n",
    "                       rr_thresholds=np.arange(1.5, 4.1, 0.5), \n",
    "                       targets=np.arange(0.001, 0.0061, 0.0005)):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Перебор всех комбинаций параметров\n",
    "    for rr in tqdm(rr_thresholds, desc='Processing rr_threshold'):\n",
    "        for target in tqdm(targets, desc='Processing target', leave=False):\n",
    "            # Создание целевой переменной с текущими параметрами\n",
    "            df_temp = df.copy()\n",
    "            df_temp = add_target_column_mod(\n",
    "                df_temp,\n",
    "                target_candles=target_candles,\n",
    "                target=target,\n",
    "                rr_threshold=rr\n",
    "            )\n",
    "            \n",
    "            # Берем только целевую переменную из модифицированного датафрейма\n",
    "            y = df_temp['target'].values\n",
    "            \n",
    "            # Разделение данных с использованием предопределенных индексов\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "            \n",
    "            # Пропускаем итерацию если в valid нет обоих классов\n",
    "            if len(np.unique(y_valid)) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Обучение модели\n",
    "            model = RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=13,\n",
    "            max_features=0.8,\n",
    "            min_samples_leaf=6,\n",
    "            min_samples_split=5,\n",
    "            max_samples=0.7,\n",
    "            min_impurity_decrease=0.0002,\n",
    "            class_weight={0: 1, 1: 5},\n",
    "            criterion='entropy',\n",
    "            bootstrap=True,\n",
    "            random_state=3,\n",
    "            n_jobs=-1)\n",
    "            # model = lgb.LGBMClassifier(\n",
    "            # num_leaves=30,\n",
    "            # max_depth=9,\n",
    "            # learning_rate=0.05,\n",
    "            # n_estimators=200,\n",
    "            # min_child_samples=50,\n",
    "            # subsample=0.5,\n",
    "            # colsample_bytree=0.8,\n",
    "            # reg_alpha=0.1,\n",
    "            # reg_lambda=0.1,\n",
    "            # scale_pos_weight=1,\n",
    "            # boosting_type='gbdt',\n",
    "            # importance_type='split',\n",
    "            # random_state=3,\n",
    "            # verbose=-1)\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Прогноз и расчет метрик\n",
    "            y_pred = model.predict(X_valid)\n",
    "            results.append({\n",
    "                'rr_threshold': rr,\n",
    "                'target': target,\n",
    "                'f1': f1_score(y_valid, y_pred),\n",
    "                'precision': precision_score(y_valid, y_pred),\n",
    "                'recall': recall_score(y_valid, y_pred),\n",
    "                'positive_ratio': np.mean(y_train)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e5f66-82a5-4c08-8050-95720ce868f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
