# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.17.2
#   kernelspec:
#     display_name: Python [conda env:base] *
#     language: python
#     name: conda-base-py
# ---

# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import (
    roc_auc_score,
    f1_score,
    precision_score,
    recall_score
)
from tabulate import tabulate
from datetime import datetime
import seaborn as sns
from tqdm import tqdm
from joblib import Parallel, delayed
import os
import shap
import time
from datetime import timedelta
from sklearn.inspection import permutation_importance
from datetime import timedelta
from sklearn.feature_selection import RFECV
from sklearn.model_selection import TimeSeriesSplit
from boruta import BorutaPy
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_classif
from statsmodels.tsa.stattools import grangercausalitytests
from sklearn.model_selection import cross_val_score
import warnings
from joblib import Parallel, delayed
from sklearn.base import clone
from concurrent.futures import ProcessPoolExecutor
from multiprocessing import cpu_count
import numpy as np
import warnings
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import f1_score
from tqdm import tqdm
import matplotlib.pyplot as plt
from .all_kline_changes import add_target_column_mod


# %% [markdown]
# **–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ F1, Precision, recall, –ø–æ—Ä–æ–≥–∞ –≤—Ö–æ–∂–¥–µ–Ω–∏—è (thrashold) –∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏**

# %%
def evaluate_model_with_threshold(model, X_train, y_train, X_valid, y_valid, X_test=None, y_test=None):
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    {
        'model': model,  # –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        'metrics': {
            'train': {–º–µ—Ç—Ä–∏–∫–∏},
            'valid': {–º–µ—Ç—Ä–∏–∫–∏},
            'test': {–º–µ—Ç—Ä–∏–∫–∏} (–µ—Å–ª–∏ –µ—Å—Ç—å),
            'optimal_threshold': float
        },
        'features': list,  # —Å–ø–∏—Å–æ–∫ —Ñ–∏—á–µ–π
        'timestamp': str   # –≤—Ä–µ–º—è –æ—Ü–µ–Ω–∫–∏
    }
    """
    from sklearn.metrics import roc_auc_score
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    y_train_proba = model.predict_proba(X_train)[:, 1]
    y_valid_proba = model.predict_proba(X_valid)[:, 1]
    
    if X_test is not None and y_test is not None:
        y_test_proba = model.predict_proba(X_test)[:, 1]
    
    # 2. –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –ø–æ—Ä–æ–≥–æ–≤
    thresholds = np.linspace(0.01, 0.99, 99)
    
    # 3. –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è F1 –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–∞—Ö
    def find_best_threshold(y_true, y_proba, thresholds):
        f1_scores = []
        for t in thresholds:
            y_pred = (y_proba >= t).astype(int)
            f1_scores.append(f1_score(y_true, y_pred, zero_division=0))
        best_idx = np.argmax(f1_scores)
        return thresholds[best_idx], f1_scores
    
    # 4. –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è train –∏ valid
    train_best_threshold, train_f1_scores = find_best_threshold(y_train, y_train_proba, thresholds)
    valid_best_threshold, valid_f1_scores = find_best_threshold(y_valid, y_valid_proba, thresholds)
    
    # 5. –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
    optimal_threshold = np.mean([train_best_threshold, valid_best_threshold])
    
    # 6. –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    train_metrics = {
        'thresholds': thresholds,
        'f1_scores': train_f1_scores,
        'precision': [precision_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],
        'recall': [recall_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],
        'y_proba': y_train_proba,
        'max_f1_threshold': train_best_threshold,
        'roc_auc': roc_auc_score(y_train, y_train_proba)  # –î–æ–±–∞–≤–ª–µ–Ω–æ ROC AUC
    }
    
    valid_metrics = {
        'thresholds': thresholds,
        'f1_scores': valid_f1_scores,
        'precision': [precision_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],
        'recall': [recall_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],
        'y_proba': y_valid_proba,
        'max_f1_threshold': valid_best_threshold,
        'roc_auc': roc_auc_score(y_valid, y_valid_proba)  # –î–æ–±–∞–≤–ª–µ–Ω–æ ROC AUC
    }
    
    # 7. –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"üéØ –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥ –ø–æ F1 (Train): {train_best_threshold:.4f}")
    print(f"üéØ –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥ –ø–æ F1 (Valid): {valid_best_threshold:.4f}")
    print(f"‚úÖ –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {optimal_threshold:.4f}")
    print(f"\nüìä ROC AUC Scores:")
    print(f"‚úÖ Train ROC AUC: {train_metrics['roc_auc']:.4f}")
    print(f"‚úÖ Valid ROC AUC: {valid_metrics['roc_auc']:.4f}")
    
    # 8. –°—á–∏—Ç–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
    def calculate_final_metrics(y_true, y_proba, threshold, set_name):
        y_pred = (y_proba >= threshold).astype(int)
        metrics = {
            'F1': f1_score(y_true, y_pred, zero_division=0),
            'Precision': precision_score(y_true, y_pred, zero_division=0),
            'Recall': recall_score(y_true, y_pred, zero_division=0),
            'ROC_AUC': roc_auc_score(y_true, y_proba)  # –î–æ–±–∞–≤–ª–µ–Ω–æ ROC AUC
        }
        print(f"\nüìä {set_name} set (Threshold = {threshold:.4f}):")
        print(f"‚úÖ F1: {metrics['F1']:.4f}")
        print(f"‚úÖ Precision: {metrics['Precision']:.4f}")
        print(f"‚úÖ Recall: {metrics['Recall']:.4f}")
        print(f"‚úÖ ROC AUC: {metrics['ROC_AUC']:.4f}")
        return metrics
    
    train_metrics['final_metrics'] = calculate_final_metrics(y_train, y_train_proba, optimal_threshold, "Train")
    valid_metrics['final_metrics'] = calculate_final_metrics(y_valid, y_valid_proba, optimal_threshold, "Valid")
    
    results = {
        'train': train_metrics,
        'valid': valid_metrics,
        'optimal_threshold': optimal_threshold
    }
    
    if X_test is not None and y_test is not None:
        test_metrics = {
            'thresholds': thresholds,
            'f1_scores': [f1_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],
            'precision': [precision_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],
            'recall': [recall_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],
            'y_proba': y_test_proba,
            'roc_auc': roc_auc_score(y_test, y_test_proba)  # –î–æ–±–∞–≤–ª–µ–Ω–æ ROC AUC
        }
        test_metrics['final_metrics'] = calculate_final_metrics(
            y_test, y_test_proba, optimal_threshold, "Test"
        )
        results['test'] = test_metrics
    
    # 9. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    plt.figure(figsize=(18, 6))
    
    # 1. –ö—Ä–∏–≤—ã–µ –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
    plt.subplot(1, 3, 1)
    plt.plot(train_metrics['thresholds'], train_metrics['precision'], label='Precision', color='blue')
    plt.plot(train_metrics['thresholds'], train_metrics['recall'], label='Recall', color='green')
    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='F1', color='red')
    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')
    plt.axvline(train_best_threshold, color='b', linestyle=':', label=f'Train Max F1: {train_best_threshold:.3f}')
    plt.title('Train Selection')
    plt.xlabel('Threshold')
    plt.ylabel('Score')
    plt.legend()
    plt.grid()
    
    # 2. –ö—Ä–∏–≤—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
    plt.subplot(1, 3, 2)
    plt.plot(valid_metrics['thresholds'], valid_metrics['precision'], label='Precision', color='blue')
    plt.plot(valid_metrics['thresholds'], valid_metrics['recall'], label='Recall', color='green')
    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='F1', color='red')
    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')
    plt.axvline(valid_best_threshold, color='orange', linestyle=':', label=f'Valid Max F1: {valid_best_threshold:.3f}')
    plt.title('Test Set')
    plt.xlabel('Threshold')
    plt.ylabel('Score')
    plt.legend()
    plt.grid()
    
    # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ F1-–∫—Ä–∏–≤—ã—Ö —Å –Ω–æ–≤—ã–º –ø–æ—Ä–æ–≥–æ–º
    plt.subplot(1, 3, 3)
    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='Train F1', color='blue')
    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='Valid F1', color='orange')
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∞ —Ç—Ä–µ—Ç—å—è –ª–∏–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
    if X_test is not None and y_test is not None:
        plt.plot(test_metrics['thresholds'], test_metrics['f1_scores'], label='Test F1', color='green')
    
    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')
    plt.axvline(train_best_threshold, color='b', linestyle=':', alpha=0.5)
    plt.axvline(valid_best_threshold, color='orange', linestyle=':', alpha=0.5)
    plt.title('F1 Comparison with Optimal Threshold')
    plt.xlabel('Threshold')
    plt.ylabel('F1 Score')
    plt.legend()
    plt.grid()
    
    plt.tight_layout()
    plt.show()
    
    # 10. –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ (–¥–æ–±–∞–≤–ª—è–µ–º ROC AUC)
    final_table = [
        ["Dataset", "Threshold Type"] + list(train_metrics['final_metrics'].keys()),
        ["Train", f"Average Optimal ({optimal_threshold:.4f})"] + list(train_metrics['final_metrics'].values()),
        ["Test", f"Average Optimal ({optimal_threshold:.4f})"] + list(valid_metrics['final_metrics'].values())
    ]
    
    if X_test is not None and y_test is not None:
        final_table.append(
            ["Test", f"Average Optimal ({optimal_threshold:.4f})"] + list(results['test']['final_metrics'].values())
        )
    
    print("\n–ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ —Å—Ä–µ–¥–Ω–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º:")
    print(tabulate(final_table, headers="firstrow", floatfmt=".4f", tablefmt="grid"))

     # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    model_package = {
        'model': model,
        'metrics': {
            'train': train_metrics['final_metrics'],
            'valid': valid_metrics['final_metrics'],
            'optimal_threshold': optimal_threshold
        },
        'features': list(X_train.columns),
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    if X_test is not None and y_test is not None:
        model_package['metrics']['test'] = results['test']['final_metrics']
    
    return model_package


# %%

# %% [markdown]
# –ê–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å —É—á–µ—Ç–æ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏

# %%
def evaluate_model_with_threshold_mod(model, X_train, y_train, X_valid, y_valid, X_test=None, y_test=None, model_type='sklearn'):
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å (ML –∏–ª–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø–æ–¥–±–æ—Ä–æ–º –ø–æ—Ä–æ–≥–∞
    
    Parameters:
    -----------
    model : object
        –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (sklearn/lightgbm –∏–ª–∏ keras)
    model_type : str
        –¢–∏–ø –º–æ–¥–µ–ª–∏: 'sklearn' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –∏–ª–∏ 'keras'
    """
    from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score
    import numpy as np
    import matplotlib.pyplot as plt
    from datetime import datetime
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏
    if model_type == 'keras':
        # –î–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        y_train_proba = model.predict(X_train, verbose=0)
        y_valid_proba = model.predict(X_valid, verbose=0)
        
        if len(y_train_proba.shape) > 1 and y_train_proba.shape[1] > 1:
            y_train_proba = y_train_proba[:, 1] if y_train_proba.shape[1] == 2 else np.argmax(y_train_proba, axis=1)
            y_valid_proba = y_valid_proba[:, 1] if y_valid_proba.shape[1] == 2 else np.argmax(y_valid_proba, axis=1)
            
        if X_test is not None and y_test is not None:
            y_test_proba = model.predict(X_test, verbose=0)
            if len(y_test_proba.shape) > 1 and y_test_proba.shape[1] > 1:
                y_test_proba = y_test_proba[:, 1] if y_test_proba.shape[1] == 2 else np.argmax(y_test_proba, axis=1)
    else:
        # –î–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö ML-–º–æ–¥–µ–ª–µ–π
        y_train_proba = model.predict_proba(X_train)[:, 1]
        y_valid_proba = model.predict_proba(X_valid)[:, 1]
        
        if X_test is not None and y_test is not None:
            y_test_proba = model.predict_proba(X_test)[:, 1]
    
    # 2. –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –ø–æ—Ä–æ–≥–æ–≤
    thresholds = np.linspace(0.01, 0.99, 99)
    
    # 3. –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –±–∞–ª–∞–Ω—Å–∞ –º–µ–∂–¥—É Precision –∏ Recall
    def find_balanced_threshold(y_true, y_proba, thresholds):
        precisions = []
        recalls = []
        for t in thresholds:
            y_pred = (y_proba >= t).astype(int)
            precisions.append(precision_score(y_true, y_pred, zero_division=0))
            recalls.append(recall_score(y_true, y_pred, zero_division=0))
        
        diff = np.abs(np.array(precisions) - np.array(recalls))
        exclude = int(len(thresholds) * 0.1)
        valid_range = range(exclude, len(thresholds)-exclude)
        
        if len(valid_range) > 0:
            best_idx = valid_range[np.argmin(diff[valid_range])]
        else:
            best_idx = np.argmin(diff)
        
        return thresholds[best_idx], precisions, recalls
    
    # 4. –ù–∞—Ö–æ–¥–∏–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
    train_balanced_threshold, train_precisions, train_recalls = find_balanced_threshold(y_train, y_train_proba, thresholds)
    valid_balanced_threshold, valid_precisions, valid_recalls = find_balanced_threshold(y_valid, y_valid_proba, thresholds)
    optimal_threshold = np.mean([train_balanced_threshold, valid_balanced_threshold])
    
    # 5. –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
    def calculate_final_metrics(y_true, y_proba, threshold, set_name):
        y_pred = (y_proba >= threshold).astype(int)
        metrics = {
            'F1': f1_score(y_true, y_pred, zero_division=0),
            'Precision': precision_score(y_true, y_pred, zero_division=0),
            'Recall': recall_score(y_true, y_pred, zero_division=0),
            'ROC_AUC': roc_auc_score(y_true, y_proba)
        }
        print(f"\nüìä {set_name} set (Threshold = {threshold:.4f}):")
        print(f"‚úÖ F1: {metrics['F1']:.4f}")
        print(f"‚úÖ Precision: {metrics['Precision']:.4f}")
        print(f"‚úÖ Recall: {metrics['Recall']:.4f}")
        print(f"‚úÖ ROC AUC: {metrics['ROC_AUC']:.4f}")
        return metrics
    
    # 6. –í—ã—á–∏—Å–ª—è–µ–º –∏ –≤—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏
    print(f"üéØ –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ (Train): {train_balanced_threshold:.4f}")
    print(f"üéØ –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ (Valid): {valid_balanced_threshold:.4f}")
    print(f"‚úÖ –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {optimal_threshold:.4f}")
    
    train_metrics = {
        'thresholds': thresholds,
        'precision': train_precisions,
        'recall': train_recalls,
        'f1_scores': [f1_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],
        'y_proba': y_train_proba,
        'balanced_threshold': train_balanced_threshold,
        'final_metrics': calculate_final_metrics(y_train, y_train_proba, optimal_threshold, "Train")
    }
    
    valid_metrics = {
        'thresholds': thresholds,
        'precision': valid_precisions,
        'recall': valid_recalls,
        'f1_scores': [f1_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],
        'y_proba': y_valid_proba,
        'balanced_threshold': valid_balanced_threshold,
        'final_metrics': calculate_final_metrics(y_valid, y_valid_proba, optimal_threshold, "Valid")
    }
    
    results = {
        'train': train_metrics,
        'valid': valid_metrics,
        'optimal_threshold': optimal_threshold
    }
    
    if X_test is not None and y_test is not None:
        test_balanced_threshold, test_precisions, test_recalls = find_balanced_threshold(y_test, y_test_proba, thresholds)
        test_metrics = {
            'thresholds': thresholds,
            'precision': test_precisions,
            'recall': test_recalls,
            'f1_scores': [f1_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],
            'y_proba': y_test_proba,
            'balanced_threshold': test_balanced_threshold,
            'final_metrics': calculate_final_metrics(y_test, y_test_proba, optimal_threshold, "Test")
        }
        results['test'] = test_metrics
    
    # 9. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –æ–±–ª–∞—Å—Ç—å –≤–æ–∫—Ä—É–≥ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
    plt.figure(figsize=(18, 6))
    
    # 1. –ö—Ä–∏–≤—ã–µ –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
    plt.subplot(1, 3, 1)
    plt.plot(train_metrics['thresholds'], train_metrics['precision'], label='Precision', color='blue')
    plt.plot(train_metrics['thresholds'], train_metrics['recall'], label='Recall', color='green')
    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='F1', color='red')
    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')
    plt.axvline(train_balanced_threshold, color='b', linestyle=':', label=f'Train Balanced: {train_balanced_threshold:.3f}')
    plt.title('Train Selection')
    plt.xlabel('Threshold')
    plt.ylabel('Score')
    plt.legend()
    plt.grid()
    
    # 2. –ö—Ä–∏–≤—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
    plt.subplot(1, 3, 2)
    plt.plot(valid_metrics['thresholds'], valid_metrics['precision'], label='Precision', color='blue')
    plt.plot(valid_metrics['thresholds'], valid_metrics['recall'], label='Recall', color='green')
    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='F1', color='red')
    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')
    plt.axvline(valid_balanced_threshold, color='orange', linestyle=':', label=f'Valid Balanced: {valid_balanced_threshold:.3f}')
    plt.title('Validation Set')
    plt.xlabel('Threshold')
    plt.ylabel('Score')
    plt.legend()
    plt.grid()
    
    # 3. Zoom –Ω–∞ –æ–±–ª–∞—Å—Ç—å –≤–æ–∫—Ä—É–≥ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
    plt.subplot(1, 3, 3)
    zoom_range = 0.2  # +/- 20% –æ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
    zoom_min = max(0.01, optimal_threshold - zoom_range)
    zoom_max = min(0.99, optimal_threshold + zoom_range)
    
    mask = (thresholds >= zoom_min) & (thresholds <= zoom_max)
    
    plt.plot(thresholds[mask], np.array(train_metrics['precision'])[mask], label='Train Precision', color='blue', linestyle='--')
    plt.plot(thresholds[mask], np.array(train_metrics['recall'])[mask], label='Train Recall', color='green', linestyle='--')
    plt.plot(thresholds[mask], np.array(valid_metrics['precision'])[mask], label='Valid Precision', color='blue')
    plt.plot(thresholds[mask], np.array(valid_metrics['recall'])[mask], label='Valid Recall', color='green')
    
    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Optimal: {optimal_threshold:.3f}')
    plt.title(f'Zoom Around Optimal Threshold ({zoom_min:.2f}-{zoom_max:.2f})')
    plt.xlabel('Threshold')
    plt.ylabel('Score')
    plt.legend()
    plt.grid()
    
    plt.tight_layout()
    plt.show()
    
    return {
        'model': model,
        'metrics': {
            'train': train_metrics['final_metrics'],
            'valid': valid_metrics['final_metrics'],
            'test': results['test']['final_metrics'] if 'test' in results else None,
            'optimal_threshold': optimal_threshold
        },
        'features': list(X_train.columns) if hasattr(X_train, 'columns') else None,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }


# %% [markdown]
# **–¢–æ—á–µ—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π**

# %%
def plot_feature_pairplot(df, features_list):
    """
    –°—Ç—Ä–æ–∏—Ç pairplot –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π 'target'
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    df : pandas.DataFrame
        –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
    features_list : list
        –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (–Ω–µ –≤–∫–ª—é—á–∞—è 'target')
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    -----------
    None (–æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫)
    """
    # –î–æ–±–∞–≤–ª—è–µ–º target –∫ —Å–ø–∏—Å–∫—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    columns_to_plot = features_list + ['target']
    
    try:
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –≤—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        subset_df = df[columns_to_plot].dropna()
        
        # –°—Ç—Ä–æ–∏–º pairplot
        sns.pairplot(subset_df, hue='target', diag_kind='kde', palette='viridis')
        plt.suptitle('Pairplot: selected features vs target', y=1.02)
        plt.show()
        
    except KeyError as e:
        print(f"–û—à–∏–±–∫–∞: –≤ DataFrame –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ {e}")
    except Exception as e:
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
# plot_feature_pairplot(df, ['senkou_span_a_norm', 'senkou_span_b_norm', 'breakout_in_5', 'atr_14_norm%', 'EFI'])


# %% [markdown]
# **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞**

# %%
import matplotlib.pyplot as plt

def plot_correlation_matrix(df, drop_columns=['Data', 'High', 'Low', 'Close', 'Open', 'Volume']):
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç—å—é –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    """
    try:
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        data = df.drop(drop_columns, axis=1, errors='ignore')
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
        corr_matrix = data.corr()
        num_features = len(corr_matrix)
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if num_features <= 15:
            figsize = (10, 8)
            font_scale = 1.2
            annot = True
            label_size = 10
        elif num_features <= 30:
            figsize = (16, 14)
            font_scale = 1.0
            annot = False
            label_size = 9
        else:  # –î–ª—è 50+ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            figsize = (20, 18)
            font_scale = 0.8
            annot = False
            label_size = 8
            # –î–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –º–µ—Ç–æ–∫
            plt.rcParams['xtick.major.pad'] = 0.5
            plt.rcParams['ytick.major.pad'] = 0.5
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
        sns.set(font_scale=font_scale)
        plt.figure(figsize=figsize)
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        heatmap = sns.heatmap(
            corr_matrix,
            cmap='coolwarm',
            annot=annot,
            fmt=".2f",
            square=True,
            linewidths=0.5,
            cbar_kws={"shrink": 0.7},
            mask=np.triu(np.ones_like(corr_matrix, dtype=bool)),
            annot_kws={"size": 8} if annot else None
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–ø–∏—Å–µ–π –æ—Å–µ–π
        heatmap.set_xticklabels(
            heatmap.get_xticklabels(),
            rotation=45,
            ha='right',
            fontsize=label_size
        )
        heatmap.set_yticklabels(
            heatmap.get_yticklabels(),
            rotation=0,
            fontsize=label_size
        )
        
        plt.title(f'–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ ({num_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)', fontsize=14)
        plt.tight_layout()
        plt.show()
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
# plot_correlation_matrix(df)


# %% [markdown]
# **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ç–æ–ø 20**

# %%
def get_top_correlated_pairs(df, top_n=20):
    # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
    corr_matrix = df.corr().abs()  # –ë–µ—Ä–µ–º –º–æ–¥—É–ª—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä (–±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è A:B –∏ B:A)
    pairs = []
    cols = corr_matrix.columns
    for i in range(len(cols)):
        for j in range(i + 1, len(cols)):  # –ò—Å–∫–ª—é—á–∞–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å –∏ –∑–µ—Ä–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ä—ã
            pairs.append((cols[i], cols[j], corr_matrix.iloc[i, j]))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–∞—Ä—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    pairs_sorted = sorted(pairs, key=lambda x: x[2], reverse=True)
    
    # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-N –ø–∞—Ä
    print(f"–¢–æ–ø-{top_n} –ø–∞—Ä –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:")
    for pair in pairs_sorted[:top_n]:
        print(f"{pair[0]} : {pair[1]} : {pair[2]:.4f}")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
# get_top_correlated_pairs(df, top_n=20)


# %% [markdown]
# **SHAP**

# %%
def explain_model_shap(X_train, model, sample_size=2000, top_n=20, n_jobs = -1):
    """
    –û–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç —Ä–∞—Å—á–µ—Ç SHAP-–≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    X_train : pd.DataFrame
        –î–∞—Ç–∞—Ñ—Ä–µ–π–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    model : sklearn/xgboost –º–æ–¥–µ–ª—å
        –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (RandomForest, LogisticRegression, XGB –∏ –¥—Ä.)
    sample_size : int
        –†–∞–∑–º–µ—Ä —Å–ª—É—á–∞–π–Ω–æ–π –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏
    top_n : int
        –ö–æ–ª-–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    try:
        total_start_time = time.time()
        model_type = type(model).__name__
        
        print(f"‚ÑπÔ∏è Model type: {model_type}")
        print(f"‚ÑπÔ∏è Number of classes: {getattr(model, 'n_classes_', 'unknown')}")
        
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Explainer
        print("üîÑ Initializing SHAP explainer...")
        explainer_start = time.time()
        if model_type in ['RandomForestClassifier', 'RandomForestRegressor', 
                          'XGBClassifier', 'XGBRegressor', 
                          'LGBMClassifier', 'LGBMRegressor']:
            explainer = shap.TreeExplainer(model, feature_perturbation="tree_path_dependent")
        elif model_type in ['LogisticRegression', 'LinearRegression']:
            explainer = shap.LinearExplainer(model, X_train)
        else:
            explainer = shap.Explainer(model, X_train)
        explainer_time = time.time() - explainer_start
        print(f"‚úÖ SHAP explainer initialized in {timedelta(seconds=explainer_time)}")
        
        # 2. –ü–æ–¥–≤—ã–±–æ—Ä–∫–∞
        sample_size = min(sample_size, len(X_train))
        sample_idx = np.random.choice(X_train.index, size=sample_size, replace=False)
        X_sample = X_train.loc[sample_idx]

        print(f"\nüîÑ Calculating SHAP values for {sample_size} samples...")
        shap_start = time.time()

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        n_jobs = n_jobs
        n_chunks = 4 * (os.cpu_count() or 1)

        def calc_chunk(chunk):
            return explainer.shap_values(chunk, approximate=True, check_additivity=False)

        chunks = np.array_split(X_sample, n_chunks)
        results = Parallel(n_jobs=n_jobs)(delayed(calc_chunk)(chunk) for chunk in chunks)

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if isinstance(results[0], list):
            shap_values = [np.concatenate([r[i] for r in results]) for i in range(len(results[0]))]
        else:
            shap_values = np.concatenate(results)

        shap_time = time.time() - shap_start
        print(f"‚úÖ SHAP values calculated in {timedelta(seconds=shap_time)}")
        print(f"‚è± Average time per sample: {shap_time/sample_size:.4f} seconds")

        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ SHAP
        if isinstance(shap_values, list):
            shap_values = shap_values[1] if len(shap_values) == 2 else np.mean(shap_values, axis=0)
        elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:
            shap_values = shap_values[:, :, 1]

        print(f"‚ÑπÔ∏è Processed SHAP values shape: {shap_values.shape}")

        # 4. –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏
        print("\nüîÑ Calculating feature importance...")
        analysis_start = time.time()
        importance_df = pd.DataFrame({
            'Feature': X_train.columns,
            'SHAP_Importance': np.abs(shap_values).mean(axis=0),
            'Direction': np.where(np.mean(shap_values, axis=0) > 0, 'Positive', 'Negative')
        })
        if hasattr(model, 'feature_importances_'):
            importance_df['Model_Importance'] = model.feature_importances_
            importance_df['Model_%'] = 100 * importance_df['Model_Importance'] / importance_df['Model_Importance'].max()

        importance_df['SHAP_%'] = 100 * importance_df['SHAP_Importance'] / importance_df['SHAP_Importance'].max()
        importance_df = importance_df.sort_values('SHAP_%', ascending=False)
        importance_df['Rank'] = range(1, len(importance_df) + 1)
        importance_df['Cumulative_SHAP_%'] = importance_df['SHAP_%'].cumsum()
        analysis_time = time.time() - analysis_start
        print(f"‚úÖ Feature analysis completed in {timedelta(seconds=analysis_time)}")

        # 5. –¢–∞–±–ª–∏—Ü–∞
        print("\nüîç Top Features by SHAP Importance:")
        display_cols = ['Rank', 'Feature', 'SHAP_%', 'Direction']
        if 'Model_%' in importance_df.columns:
            display_cols.append('Model_%')
        print(importance_df.head(top_n)[display_cols].to_markdown(index=False, floatfmt=".1f"))

        print("\nüìä Key Metrics:")
        print(f"‚Ä¢ Top-5 features explain: {importance_df['Cumulative_SHAP_%'].iloc[4]:.1f}%")
        pos_count = (importance_df['Direction'] == 'Positive').sum()
        neg_count = (importance_df['Direction'] == 'Negative').sum()
        print(f"‚Ä¢ Positive/Negative: {pos_count}/{neg_count}")

        # 6. –ü—Ä–æ—Å—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        plt.figure(figsize=(10, min(6, top_n * 0.3)))
        colors = importance_df['Direction'].head(top_n).map({'Positive': 'tomato', 'Negative': 'dodgerblue'})
        plt.barh(importance_df['Feature'].head(top_n)[::-1], 
                 importance_df['SHAP_%'].head(top_n)[::-1],
                 color=colors[::-1])
        plt.title(f'Top {top_n} Features by SHAP')
        plt.xlabel('Relative SHAP Importance (%)')
        plt.tight_layout()
        plt.show()

        # 7. –û–±—â–µ–µ –≤—Ä–µ–º—è
        total_time = time.time() - total_start_time
        print(f"\n‚è± Total execution time: {timedelta(seconds=total_time)}")
        print("="*50)
        print("Time breakdown:")
        print(f"- Explainer init: {timedelta(seconds=explainer_time)}")
        print(f"- SHAP values: {timedelta(seconds=shap_time)} ({shap_time/total_time*100:.1f}%)")
        print(f"- Analysis: {timedelta(seconds=analysis_time)} ({analysis_time/total_time*100:.1f}%)")

        return importance_df

    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        if 'shap_values' in locals():
            print(f"SHAP values type: {type(shap_values)}")
            if hasattr(shap_values, 'shape'):
                print(f"SHAP values shape: {shap_values.shape}")
        print(f"X_train shape: {X_train.shape if X_train is not None else 'N/A'}")
        if hasattr(model, 'n_features_in_'):
            print(f"Model features: {model.n_features_in_}")
        return None
# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
# explain_model_shap(X_train, logreg_model)
# explain_model_shap(X_train, rf_model, sample_size=2000)


# %% [markdown]
# **Permutation importance (—Ä–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∏ –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏)**

# %%
def explain_model_permutation(X, y, model, scoring='f1', n_repeats=5, top_n=20, random_state=3):
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é Permutation Importance.
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    X : pd.DataFrame
        –ü—Ä–∏–∑–Ω–∞–∫–∏ (X_train –∏–ª–∏ X_valid)
    y : pd.Series
        –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
    model : –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        RandomForest, LogisticRegression, XGBoost –∏ —Ç.–¥.
    scoring : str
        –ú–µ—Ç—Ä–∏–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'f1', 'accuracy', 'roc_auc')
    n_repeats : int
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏
    top_n : int
        –ö–æ–ª-–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    random_state : int
        –°–ª—É—á–∞–π–Ω–æ–µ –∑–µ—Ä–Ω–æ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    -----------
    pd.DataFrame ‚Äî —Ç–∞–±–ª–∏—Ü–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    try:
        print(f"‚ÑπÔ∏è Model type: {type(model).__name__}")
        print(f"‚ÑπÔ∏è Scoring metric: {scoring}")

        start_time = time.time()

        # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
        n_jobs = os.cpu_count() - 1 if os.cpu_count() else 1

        print("üîÑ Calculating permutation importance...")
        result = permutation_importance(
            model, X, y,
            scoring=scoring,
            n_repeats=n_repeats,
            random_state=random_state,
            n_jobs=n_jobs
        )

        elapsed = time.time() - start_time
        print(f"‚úÖ Completed in {timedelta(seconds=elapsed)}")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
        importances_df = pd.DataFrame({
            'Feature': X.columns,
            'Mean Importance': result.importances_mean,
            'Std': result.importances_std
        })
        importances_df['Significant'] = importances_df['Mean Importance'] - 2 * importances_df['Std'] > 0
        importances_df = importances_df.sort_values(by='Mean Importance', ascending=False).reset_index(drop=True)
        importances_df['Rank'] = importances_df.index + 1

        print("\nüîç Top Features by Permutation Importance:")
        display_cols = ['Rank', 'Feature', 'Mean Importance', 'Std', 'Significant']
        print(importances_df.head(top_n)[display_cols].to_markdown(index=False, floatfmt=".3f"))

        # –ü—Ä–æ—Å—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        top_features = importances_df.head(top_n)
        plt.figure(figsize=(10, min(6, top_n * 0.3)))
        bars = plt.barh(top_features['Feature'][::-1], top_features['Mean Importance'][::-1],
                        xerr=top_features['Std'][::-1], color='mediumseagreen')
        plt.xlabel("Mean Importance")
        plt.title(f"Top {top_n} Features by Permutation Importance")
        plt.tight_layout()
        plt.show()

        return importances_df

    except Exception as e:
        print(f"‚ùå Error during permutation importance: {e}")
        return None


# %% [markdown]
# **RFECV**

# %%
def show_rfecv_results(X_train, y_train, estimator, 
                      scoring='f1', step=1, n_splits=3, 
                      n_jobs=-1, verbose=0):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é RFECV –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:
    - —Å–ø–∏—Å–æ–∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    - –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    X_train : pd.DataFrame –∏–ª–∏ array-like
        –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    y_train : pd.Series –∏–ª–∏ array-like
        –í–µ–∫—Ç–æ—Ä —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    estimator : –æ–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏
        –£–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, RandomForestClassifier())
    scoring : str, default='f1'
        –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    step : int, default=1
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—è–µ–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
    n_splits : int, default=3
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è TimeSeriesSplit
    n_jobs : int, default=-1
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–¥–µ—Ä –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    verbose : int, default=0
        –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—ã–≤–æ–¥–∞
    """
    
    # TimeSeries split
    tscv = TimeSeriesSplit(n_splits=n_splits)
    
    # RFECV —Å –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é –∏ TSCV
    rfecv_selector = RFECV(
        estimator=estimator,
        step=step,
        cv=tscv,
        scoring=scoring,
        verbose=verbose,
        n_jobs=n_jobs
    )
    
    # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
    X_rfecv = X_train.copy() if isinstance(X_train, pd.DataFrame) else X_train
    y_rfecv = y_train.copy()
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    rfecv_selector.fit(X_rfecv, y_rfecv)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    if isinstance(X_train, pd.DataFrame):
        rfecv_features = X_train.columns[rfecv_selector.support_].tolist()
    else:
        rfecv_features = [f"feature_{i}" for i, selected in enumerate(rfecv_selector.support_) if selected]
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏, –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ RFECV:")
    print(rfecv_features)
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫
    plt.figure(figsize=(10, 5))
    plt.plot(range(1, len(rfecv_selector.cv_results_['mean_test_score']) + 1),
             rfecv_selector.cv_results_['mean_test_score'])
    plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    plt.ylabel(f"{scoring} score")
    plt.title(f"–ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ ({estimator.__class__.__name__}) –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (RFECV)")
    plt.grid(True)
    plt.show()


# %% [markdown]
# **Boruta**

# %%
def explain_model_boruta(
    X_train, 
    X_valid, 
    y_train, 
    y_valid, 
    model, 
    max_iter=100, 
    n_splits=3, 
    random_state=3,
    perc=100,
    alpha=0.05,
    two_step=True,
    n_estimators='auto',
    verbose=0
):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é Boruta –∏ TimeSeriesSplit.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    X_train : pd.DataFrame
        –ü—Ä–∏–∑–Ω–∞–∫–∏ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
    X_valid : pd.DataFrame
        –ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –≤–∫–ª—é—á–µ–Ω –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è)
    y_train : pd.Series
        –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
    y_valid : pd.Series
        –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    model : –æ–±—ä–µ–∫—Ç
        –û–±—É—á–∞–µ–º–∞—è –º–æ–¥–µ–ª—å (RandomForest, XGBoost, LogisticRegression –∏ –¥—Ä.)
    max_iter : int, default=100
        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π Boruta (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º —Ç—â–∞—Ç–µ–ª—å–Ω–µ–µ –æ—Ç–±–æ—Ä,
        –Ω–æ –¥–æ–ª—å—à–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ)
    n_splits : int, default=3
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–±–∏–µ–Ω–∏–π –≤ TimeSeriesSplit (–¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
    random_state : int, default=3
        –ó–µ—Ä–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    perc : int, default=100
        –ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —à—É–º–æ–º (–º–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–µ–ª–∞—é—Ç
        –æ—Ç–±–æ—Ä –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º)
    alpha : float, default=0.05
        –£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –¥–ª—è –æ—Ç–±—Ä–∞–∫–æ–≤–∫–∏ –≥–∏–ø–æ—Ç–µ–∑ (–º–µ–Ω—å—à–µ = —Å—Ç—Ä–æ–∂–µ –æ—Ç–±–æ—Ä)
    two_step : bool, default=True
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—É—é –ø—Ä–æ—Ü–µ–¥—É—Ä—É (True —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö)
    n_estimators : int –∏–ª–∏ 'auto', default='auto'
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –∞–Ω—Å–∞–º–±–ª–µ (–µ—Å–ª–∏ 'auto', –±–µ—Ä–µ—Ç—Å—è –∏–∑ –º–æ–¥–µ–ª–∏)
    verbose : int, default=0
        –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—ã–≤–æ–¥–∞ (0 - –Ω–µ—Ç –≤—ã–≤–æ–¥–∞, 1 - –±–∞–∑–æ–≤—ã–π, 2 - –ø–æ–¥—Ä–æ–±–Ω—ã–π)
    """
    try:
        print(f"‚ÑπÔ∏è Model type: {type(model).__name__}")
        print(f"‚ÑπÔ∏è Boruta params: max_iter={max_iter}, perc={perc}, alpha={alpha}")
        print(f"‚ÑπÔ∏è TimeSeriesSplit n_splits: {n_splits}")

        X_df = X_train.copy()
        X_array, y_array = X_df.values, y_train.values

        tscv = TimeSeriesSplit(n_splits=n_splits)

        boruta = BorutaPy(
            estimator=model,
            n_estimators=n_estimators,
            verbose=verbose,
            random_state=random_state,
            max_iter=max_iter,
            perc=perc,
            alpha=alpha,
            two_step=two_step
        )

        print("üîÑ Running Boruta feature selection on time series splits...")

        support_masks = []
        for i, (train_idx, test_idx) in enumerate(tscv.split(X_array)):
            print(f"  ‚Ä¢ Fold {i+1}/{n_splits} ‚Äî Train size: {len(train_idx)}, Test size: {len(test_idx)}")
            X_fold_train, y_fold_train = X_array[train_idx], y_array[train_idx]
            boruta.fit(X_fold_train, y_fold_train)
            support_masks.append(boruta.support_.copy())

        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –º–∞—Å–æ–∫ –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º
        final_support = np.all(support_masks, axis=0)
        selected_features = X_df.columns[final_support].tolist()

        print(f"\n‚úÖ –ò—Ç–æ–≥–æ–≤—ã–µ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(selected_features)}):")
        for i, feat in enumerate(selected_features, 1):
            print(f"{i:>2}. {feat}")

        return selected_features

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ Boruta: {str(e)}")
        return None


# %% [markdown]
# **Mutual Information (–≤–∑–∞–∏–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)**

# %%
def explain_model_mutual_info(X_train, y_train, top_n=20, random_state=3):
    """
    –†–∞—Å—á—ë—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ Mutual Information.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    X_train : pd.DataFrame
        –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    y_train : pd.Series
        –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
    top_n : int
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    random_state : int
        –ó–µ—Ä–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª –¥–ª—è MI-–æ—Ü–µ–Ω–∫–∏
    """
    try:
        start_time = time.time()
        print(f"‚ÑπÔ∏è Calculating Mutual Information for {X_train.shape[1]} features...")

        # 1. –†–∞—Å—á—ë—Ç MI
        mi_scores = mutual_info_classif(X_train, y_train, random_state=random_state)
        mi_df = pd.DataFrame({
            'Feature': X_train.columns,
            'MI_Score': mi_scores
        }).sort_values('MI_Score', ascending=False)

        elapsed_time = time.time() - start_time
        print(f"‚úÖ MI calculation completed in {elapsed_time:.2f} seconds")

        # 2. –¢–∞–±–ª–∏—Ü–∞ —Ç–æ–ø-N
        print(f"\nüîç Top {top_n} Features by Mutual Information:")
        print(mi_df.head(top_n).to_markdown(index=False, floatfmt=".4f"))

        # 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        plt.figure(figsize=(10, min(6, top_n * 0.3)))
        plt.barh(mi_df['Feature'].head(top_n)[::-1], 
                 mi_df['MI_Score'].head(top_n)[::-1], 
                 color='skyblue')
        plt.xlabel('Mutual Information Score')
        plt.title(f'Top {top_n} Features by Mutual Information')
        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á—ë—Ç–µ Mutual Information: {str(e)}")


# %% [markdown]
# **Granger Causality (–ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å –ø–æ –ì—Ä–µ–π–Ω–¥–∂–µ—Ä—É)**

# %%
def explain_model_granger(X_train, y_train, target_name='target', max_lag=5, top_n=20):
    """
    –ê–Ω–∞–ª–∏–∑ Granger Causality –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    ----------
    X_train : pd.DataFrame
        –ü—Ä–∏–∑–Ω–∞–∫–∏ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
    y_train : pd.Series
        –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
    target_name : str
        –ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–¥–ª—è –ø–æ–¥–ø–∏—Å–∏)
    max_lag : int
        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–≥–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞ –ì—Ä–µ–π–Ω–¥–∂–µ—Ä–∞
    top_n : int
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    try:
        start_time = time.time()
        print(f"‚ÑπÔ∏è Calculating Granger causality for {X_train.shape[1]} features...")

        def check_granger_causality(feature_series, target_series, max_lag=5):
            data = pd.DataFrame({
                'target': target_series,
                'feature': feature_series
            }).dropna()
            try:
                test_result = grangercausalitytests(data[['target', 'feature']], maxlag=max_lag, verbose=False)
                p_values = [test_result[i+1][0]['ssr_chi2test'][1] for i in range(max_lag)]
                return np.min(p_values)
            except:
                return np.nan  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–µ—Ä–Ω—É—Ç—å NaN

        granger_results = {
            feature: check_granger_causality(X_train[feature], y_train)
            for feature in X_train.columns
        }

        granger_df = pd.DataFrame({
            'Feature': list(granger_results.keys()),
            'Granger_p_value': list(granger_results.values())
        }).dropna().sort_values('Granger_p_value')

        elapsed_time = time.time() - start_time
        print(f"‚úÖ Granger analysis completed in {elapsed_time:.2f} seconds")

        # –í—ã–≤–æ–¥ —Ç–∞–±–ª–∏—Ü—ã
        print(f"\nüîç Top {top_n} Features by Granger Causality (lowest p-values):")
        print(granger_df.head(top_n).to_markdown(index=False, floatfmt=".4e"))

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        plt.figure(figsize=(10, min(6, top_n * 0.3)))
        plt.barh(granger_df['Feature'].head(top_n)[::-1],
                 -np.log10(granger_df['Granger_p_value'].head(top_n)[::-1]),
                 color='salmon')
        plt.xlabel(r'$-\log_{10}$(p-value)')
        plt.title(f'Top {top_n} Features by Granger Causality vs "{target_name}"')
        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ Granger Causality: {str(e)}")


# %% [markdown]
# **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å F1 –º–æ–¥–µ–ª–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–µ—Ä–µ–≤—å–µ–≤**

# %%
def evaluate_n(n, base_model, cv_splits, X_train_arr, y_train_arr):
    """–ì–ª–æ–±–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ —Å –∑–∞–¥–∞–Ω–Ω—ã–º n_estimators."""
    model = clone(base_model).set_params(
        n_estimators=n,
        warm_start=True,  # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
        verbose=0
    )
    scores = []
    for train_idx, test_idx in cv_splits:
        X_train_fold = X_train_arr[train_idx]
        X_test_fold = X_train_arr[test_idx]
        y_train_fold = y_train_arr[train_idx]
        y_test_fold = y_train_arr[test_idx]
        
        model.fit(X_train_fold, y_train_fold)
        pred = model.predict(X_test_fold)
        scores.append(f1_score(y_test_fold, pred))
    return np.mean(scores)

def plot_f1_vs_n_estimators(X_train, y_train, base_model, 
                          n_estimators_range=(100, 1000), step=50, 
                          n_splits=3, n_jobs=-1):
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º joblib.Parallel.
    """
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if not hasattr(base_model, 'fit') or not hasattr(base_model, 'predict'):
        raise ValueError("base_model –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–æ–¥–µ–ª—å—é scikit-learn —Å –º–µ—Ç–æ–¥–∞–º–∏ fit –∏ predict")
    
    n_estimators_values = np.arange(
        n_estimators_range[0], 
        n_estimators_range[1] + 1, 
        step
    )
    
    tscv = TimeSeriesSplit(n_splits=n_splits)
    cv_splits = list(tscv.split(X_train))
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ numpy array –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    X_train_arr = X_train.values if hasattr(X_train, 'iloc') else X_train
    y_train_arr = y_train.values if hasattr(y_train, 'iloc') else y_train
    
    # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        
        print(f"‚è≥ –ê–Ω–∞–ª–∏–∑ {len(n_estimators_values)} –∑–Ω–∞—á–µ–Ω–∏–π n_estimators...")
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ joblib
        f1_scores = Parallel(n_jobs=n_jobs, backend="loky")(
            delayed(evaluate_n)(
                n, base_model, cv_splits, X_train_arr, y_train_arr
            ) for n in tqdm(n_estimators_values, desc="n_estimators")
        )
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è NaN —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        valid_mask = ~np.isnan(f1_scores)
        n_estimators_values = n_estimators_values[valid_mask]
        f1_scores = np.array(f1_scores)[valid_mask]
        
        if not len(f1_scores):
            print("‚ö†Ô∏è –í—Å–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —Å –æ—à–∏–±–∫–æ–π!")
            return
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
        plt.figure(figsize=(12, 6))
        plt.plot(n_estimators_values, f1_scores, 'b-o', alpha=0.7)
        plt.title(f'–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å F1 –æ—Ç n_estimators ({base_model.__class__.__name__})')
        plt.xlabel('n_estimators')
        plt.ylabel('F1-score (CV —Å—Ä–µ–¥–Ω–µ–µ)')
        plt.grid(True, linestyle='--', alpha=0.5)
        
        best_idx = np.argmax(f1_scores)
        plt.scatter(
            n_estimators_values[best_idx], f1_scores[best_idx],
            color='red', s=150, zorder=5,
            label=f'–õ—É—á—à–µ–µ: {f1_scores[best_idx]:.4f} (n={n_estimators_values[best_idx]})'
        )
        
        plt.legend()
        plt.tight_layout()
        plt.show()
        
        print(f"‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤: {n_estimators_values[best_idx]} —Å F1={f1_scores[best_idx]:.4f}")


# %% [markdown]
# **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –≤–Ω—É—Ç—Ä–∏ –≤—ã–±–æ—Ä–æ–∫**

# %%
def show_class_balance(y, y_train, y_valid, y_test):
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—É
    balance_df = pd.DataFrame({
        '–í–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç': y.value_counts(normalize=True).round(3),
        '–û–±—É—á–∞—é—â–∞—è': y_train.value_counts(normalize=True).round(3),
        '–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è': y_valid.value_counts(normalize=True).round(3),
        '–¢–µ—Å—Ç–æ–≤–∞—è': y_test.value_counts(normalize=True).round(3)
    }).fillna(0)  # –Ω–∞ —Å–ª—É—á–∞–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Å–æ–≤
    
    # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É –≤ —Å—Ç–∏–ª–µ "plain"
    print("üìä –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ (–¥–æ–ª–∏):")
    print(
        balance_df.to_markdown(
            tablefmt="simple",  # –ß–∏—Å—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ª–∏–Ω–∏–π
            stralign="center",  # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ —Ü–µ–Ω—Ç—Ä—É
            floatfmt=".3f"       # –§–æ—Ä–º–∞—Ç —á–∏—Å–µ–ª
        )
    )
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(10, 5))
    balance_df.plot(kind='bar', width=0.8, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
    plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ –≤—ã–±–æ—Ä–∫–∞–º', pad=20)
    plt.ylim(0, 1)
    plt.ylabel('–î–æ–ª—è –∫–ª–∞—Å—Å–∞')
    plt.xticks(rotation=0)
    plt.grid(axis='y', linestyle='--', alpha=0.3)
    plt.legend(framealpha=0.9)
    plt.tight_layout()
    plt.show()


# %% [markdown]
# **–ü–æ–¥–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ä–∏—Å–∫ –ø—Ä–∏–±—ã–ª—å**

# %%
def evaluate_parameters(df, X, train_index, valid_index, 
                       target_candles=20,
    
                       rr_thresholds=np.arange(1.5, 4.1, 0.5), 
                       targets=np.arange(0.001, 0.0061, 0.0005)):
    
    results = []
    
    # –ü–µ—Ä–µ–±–æ—Ä –≤—Å–µ—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    for rr in tqdm(rr_thresholds, desc='Processing rr_threshold'):
        for target in tqdm(targets, desc='Processing target', leave=False):
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å —Ç–µ–∫—É—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            df_temp = df.copy()
            df_temp = add_target_column_mod(
                df_temp,
                target_candles=target_candles,
                target=target,
                rr_threshold=rr
            )
            
            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏–∑ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞
            y = df_temp['target'].values
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]
            y_train, y_valid = y[train_index], y[valid_index]
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Ç–µ—Ä–∞—Ü–∏—é –µ—Å–ª–∏ –≤ valid –Ω–µ—Ç –æ–±–æ–∏—Ö –∫–ª–∞—Å—Å–æ–≤
            if len(np.unique(y_valid)) < 2:
                continue
                
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model = RandomForestClassifier(
            n_estimators=400,
            max_depth=13,
            max_features=0.8,
            min_samples_leaf=6,
            min_samples_split=5,
            max_samples=0.7,
            min_impurity_decrease=0.0002,
            class_weight={0: 1, 1: 5},
            criterion='entropy',
            bootstrap=True,
            random_state=3,
            n_jobs=-1)
            # model = lgb.LGBMClassifier(
            # num_leaves=30,
            # max_depth=9,
            # learning_rate=0.05,
            # n_estimators=200,
            # min_child_samples=50,
            # subsample=0.5,
            # colsample_bytree=0.8,
            # reg_alpha=0.1,
            # reg_lambda=0.1,
            # scale_pos_weight=1,
            # boosting_type='gbdt',
            # importance_type='split',
            # random_state=3,
            # verbose=-1)
            
            model.fit(X_train, y_train)
            
            # –ü—Ä–æ–≥–Ω–æ–∑ –∏ —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            y_pred = model.predict(X_valid)
            results.append({
                'rr_threshold': rr,
                'target': target,
                'f1': f1_score(y_valid, y_pred),
                'precision': precision_score(y_valid, y_pred),
                'recall': recall_score(y_valid, y_pred),
                'positive_ratio': np.mean(y_train)
            })
    
    return pd.DataFrame(results)

# %%
