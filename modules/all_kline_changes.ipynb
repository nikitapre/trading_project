{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95f6d61-f777-41d0-9836-59a5bb6117c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expit\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindicators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (add_breakout_flags,\n\u001b[0;32m     16\u001b[0m     get_fibonacci_flags,\n\u001b[0;32m     17\u001b[0m     calc_stochastic_rsi,\n\u001b[0;32m     18\u001b[0m     find_bullish_rsi_divergence,\n\u001b[0;32m     19\u001b[0m     add_normalized_volume_profile,\n\u001b[0;32m     20\u001b[0m     add_volume_filter,\n\u001b[0;32m     21\u001b[0m     add_atr_normalized, add_normalized_ichimoku, add_normalized_ichimoku_on_rsi, add_normalized_ichimoku_htf,\n\u001b[0;32m     22\u001b[0m     compute_atr_trailing,\n\u001b[0;32m     23\u001b[0m     compute_trix_elder,\n\u001b[0;32m     24\u001b[0m     compute_combined_indicators,\n\u001b[0;32m     25\u001b[0m     different_MA,\n\u001b[0;32m     26\u001b[0m     VWAP,\n\u001b[0;32m     27\u001b[0m     add_liquidity_imbalance, add_hidden_divergence,\n\u001b[0;32m     28\u001b[0m     add_price_acceleration,\n\u001b[0;32m     29\u001b[0m     quarter_theory, add_all_features, kagi_conversion_line, calculate_LISS,add_breakdown_flags,\n\u001b[0;32m     30\u001b[0m     hurst_exponent, sample_entropy, dominant_frequency, nar_residual, wasserstein_distance, Keltner_func,\n\u001b[0;32m     31\u001b[0m     compute_cmf, compute_rsi, super_trend, fibo_dinamic, add_structural_features, add_macd, add_volume_features, add_candle_vol_size_features,\n\u001b[0;32m     32\u001b[0m     different_EMA, calculate_rsi_slope, calculate_atr_slope, calculate_atr_ema_normalized, add_choppiness_index, add_bollinger_features, bollinger_awesome_alert,\n\u001b[0;32m     33\u001b[0m     add_parabolic_sar_feature, add_wave_phase_position, add_fft_phase_position, adaptive_zscore, quantile_position, atr_position, rsi_stochastic_hybrid,\n\u001b[0;32m     34\u001b[0m     add_close_window_norm_pca, add_close_window_columns, add_atr_24_norm_dynamics, add_volume_dynamics, rsi_divergence, ppo, TMA_Overlay, EWO, fibo_3_lines_dinamic, VW_MACD, Adaptive_RSI,\n\u001b[0;32m     35\u001b[0m     add_atr_features, add_atr_regimes, add_price_atr_interaction, atr_local_extremes, add_atr_normalized_rsi_weight,\n\u001b[0;32m     36\u001b[0m     different_EMA_binary, VWAP_binary, volume_base_indicators, volume_base_indicators_binary, bullish_volume_dominance_binary, add_rsi_level_signal,\n\u001b[0;32m     37\u001b[0m     add_support_resistance_features, fib_dist_050_last50, add_vwap_features_with_norm, calculate_resistance_distance, calculate_support_distance\n\u001b[0;32m     38\u001b[0m     \n\u001b[0;32m     39\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from scipy.stats import linregress\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import wasserstein_distance  # Альтернатива, если нет POT\n",
    "import ot\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import expit\n",
    "from .indicators import (add_breakout_flags,\n",
    "    get_fibonacci_flags,\n",
    "    calc_stochastic_rsi,\n",
    "    find_bullish_rsi_divergence,\n",
    "    add_normalized_volume_profile,\n",
    "    add_volume_filter,\n",
    "    add_atr_normalized, add_normalized_ichimoku, add_normalized_ichimoku_on_rsi, add_normalized_ichimoku_htf,\n",
    "    compute_atr_trailing,\n",
    "    compute_trix_elder,\n",
    "    compute_combined_indicators,\n",
    "    different_MA,\n",
    "    VWAP,\n",
    "    add_liquidity_imbalance, add_hidden_divergence,\n",
    "    add_price_acceleration,\n",
    "    quarter_theory, add_all_features, kagi_conversion_line, calculate_LISS,add_breakdown_flags,\n",
    "    hurst_exponent, sample_entropy, dominant_frequency, nar_residual, wasserstein_distance, Keltner_func,\n",
    "    compute_cmf, compute_rsi, super_trend, fibo_dinamic, add_structural_features, add_macd, add_volume_features, add_candle_vol_size_features,\n",
    "    different_EMA, calculate_rsi_slope, calculate_atr_slope, calculate_atr_ema_normalized, add_choppiness_index, add_bollinger_features, bollinger_awesome_alert,\n",
    "    add_parabolic_sar_feature, add_wave_phase_position, add_fft_phase_position, adaptive_zscore, quantile_position, atr_position, rsi_stochastic_hybrid,\n",
    "    add_close_window_norm_pca, add_close_window_columns, add_atr_24_norm_dynamics, add_volume_dynamics, rsi_divergence, ppo, TMA_Overlay, EWO, fibo_3_lines_dinamic, VW_MACD, Adaptive_RSI,\n",
    "    add_atr_features, add_atr_regimes, add_price_atr_interaction, atr_local_extremes, add_atr_normalized_rsi_weight,\n",
    "    different_EMA_binary, VWAP_binary, volume_base_indicators, volume_base_indicators_binary, bullish_volume_dominance_binary, add_rsi_level_signal,\n",
    "    add_support_resistance_features, fib_dist_050_last50, add_vwap_features_with_norm, calculate_resistance_distance, calculate_support_distance\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53bba1-042a-4242-8d96-900c313632c6",
   "metadata": {},
   "source": [
    "### Модифицированный y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061ff598-c00f-42fe-a31e-204d9bec1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_column_mod(\n",
    "    df,\n",
    "    target_candles=20,\n",
    "    target=0.04,\n",
    "    rr_threshold=2.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Присваивает y=1 всем свечам, где в следующие N свечей:\n",
    "    - цена достигает TP раньше, чем SL (или SL не достигается вообще).\n",
    "    Если TP и SL достигаются на одной свече — SL считается приоритетным (y=0).\n",
    "    \"\"\"\n",
    "    close = df['Close'].values\n",
    "    high = df['High'].values\n",
    "    low = df['Low'].values\n",
    "    y = np.zeros(len(df), dtype=int)\n",
    "\n",
    "    sl_pct = target / rr_threshold  # SL = target / rr_threshold\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        entry_price = close[i]\n",
    "        tp_price = entry_price * (1 + target)\n",
    "        sl_price = entry_price * (1 - sl_pct)\n",
    "\n",
    "        window_end = min(i + target_candles + 1, len(df))\n",
    "        tp_hit_first = False\n",
    "\n",
    "        for j in range(i + 1, window_end):\n",
    "            hit_sl = low[j] <= sl_price\n",
    "            hit_tp = high[j] >= tp_price\n",
    "\n",
    "            if hit_sl and hit_tp:\n",
    "                # SL и TP на одной свече → SL считается первым → y=0\n",
    "                break\n",
    "            elif hit_sl:\n",
    "                # SL раньше → y=0\n",
    "                break\n",
    "            elif hit_tp:\n",
    "                # TP раньше → y=1\n",
    "                tp_hit_first = True\n",
    "                break\n",
    "\n",
    "        if tp_hit_first:\n",
    "            y[i] = 1\n",
    "\n",
    "    df['target'] = y\n",
    "    return df\n",
    "#Пример как вызвать\n",
    "# df = add_target_column_no_overlap(\n",
    "#         df,\n",
    "#         target_pct=0.025,\n",
    "#         target_candles=20,\n",
    "#         rr_threshold=2.0\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7065b63-8090-4766-8f02-f249d3d7503f",
   "metadata": {},
   "source": [
    "### Добавление основных индикаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f83a9520-ff34-4260-b355-73343b25163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_main_indicators(df, length=20, eps=1e-8):\n",
    "    if df is None or df.empty:\n",
    "        raise ValueError(\"Input DataFrame is None or empty\")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df['RSI21'] = ta.rsi(df['Close'], length=21) / 100\n",
    "        df['RSI_50_21_diff'] = (ta.rsi(df['Close'], length=50) / 100) - df['RSI21']\n",
    "        \n",
    "        deviations = different_EMA(df)\n",
    "        # Объединяем с исходным DataFrame (по индексу)\n",
    "        df = pd.concat([df, deviations], axis=1)\n",
    "        df = add_vwap_features_with_norm(df)\n",
    "        df = VWAP(df)\n",
    "        df['dump_return_15'] = ta.ema(df['Close'], 9).pct_change(periods=15) / 100\n",
    "        df['fib_dist_050_last50'] = fib_dist_050_last50(df)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in apply_main_indicators: {str(e)}\")\n",
    "        return None  # Или return df для частичных результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918aee1b-dfa0-4520-b2bc-8a46b5082178",
   "metadata": {},
   "source": [
    "### Добавочные Индикаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83eee66-b432-457d-96e0-a0275d06635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_add_indicators(df, length=20, eps=1e-8):\n",
    "    if df is None or df.empty:\n",
    "        raise ValueError(\"Input DataFrame is None or empty\")\n",
    "\n",
    "    try:\n",
    "        print(f'Начальное количество NaN в df: {df.isna().sum().sum()}')\n",
    "        t0 = time.time()\n",
    "        df = add_atr_normalized(df, windows=[24], normalization_window=200)\n",
    "        print(f\"⏱️ resistance_slope_dist_200: {time.time() - t0:.2f} сек\")\n",
    "\n",
    "        \n",
    "       \n",
    "        print(f'Итоговое количество NaN в df: {df.isna().sum().sum()}')\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in apply_add_indicators: {str(e)}\")\n",
    "        return df  # Лучше вернуть df, пусть даже частично заполненный"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c27ec6-91ac-4661-8996-ad38cc78a4d4",
   "metadata": {},
   "source": [
    "### Добавление индикаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98ab62d0-1fc2-4785-8d56-de2e976b95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_indicators(df, length):\n",
    "    \n",
    "    eps = 1e-8\n",
    "    timings = {}\n",
    "\n",
    "    # Ценовой lag + z-score\n",
    "    t0 = time.time()\n",
    "    # ======Лаг цены======        \n",
    "    window = 100  # Размер скользящего окна для статистик\n",
    "    lags = [1, 3, 8]  # Лаги для разностных признаков\n",
    "    log_lags = [1, 5, 8]  # Лаги для логарифмических признаков\n",
    "        \n",
    "    # 1. Разностные признаки с rolling-статистиками c window/5\n",
    "    for lag in lags:\n",
    "        df[f'Close_lag{lag}_diff_ratio'] = (\n",
    "            (df['Close'].shift(lag) - df['Close'].shift(lag + 1)) / \n",
    "            (df['Close'].shift(lag + 1).rolling(window // 5).mean() + eps)\n",
    "        )            \n",
    "    # 2. Логарифмические признаки с защитой от нуля\n",
    "    for lag in log_lags:\n",
    "        df[f'Close_log_lag{lag}'] = np.log(\n",
    "            np.abs(df['Close'].shift(lag)) / \n",
    "            (df['Close'].shift(lag).rolling(window).mean() + eps)\n",
    "        )\n",
    "    # =========================================================\n",
    "    timings['lag + z-score'] = time.time() - t0\n",
    "\n",
    "    #Ускорение изм цены\n",
    "    df = add_price_acceleration(df)\n",
    "\n",
    "\n",
    "    # Линейная регрессия\n",
    "    t0 = time.time()\n",
    "    # Вычисление линейной регрессии с помощью pandas_ta\n",
    "    df['linreg'] = ta.linreg(close=df['Close'], length=length) / (df['Close'] + eps) - 1\n",
    "    df['linreg_lag'] = df['linreg'].shift(length)\n",
    "    timings['linreg'] = time.time() - t0\n",
    "\n",
    "    # Объем: производные\n",
    "    t0 = time.time()\n",
    "    df = add_volume_features(df, window=20)\n",
    "    avg_volume = df['Volume'].rolling(20).mean()\n",
    "    df['accel_volume'] = df['Volume'].diff(5).diff() / (avg_volume + eps)\n",
    "    df['accel_volume_fast'] = df['Volume'].diff().diff() / (avg_volume + eps)\n",
    "    timings['accel_volume'] = time.time() - t0\n",
    "\n",
    "    # Пробой\n",
    "    t0 = time.time()\n",
    "    df = add_breakout_flags(df, resistance_window=50, lookback=int(length / 2))\n",
    "    timings['breakout'] = time.time() - t0\n",
    "\n",
    "    # Фибоначчи\n",
    "    # t0 = time.time()\n",
    "    # fib_flags = get_fibonacci_flags(df, window=300, threshold=0.05)\n",
    "    # df = pd.concat([df, fib_flags], axis=1)\n",
    "    # timings['fibonacci'] = time.time() - t0\n",
    "\n",
    "    # RSI\n",
    "    t0 = time.time()\n",
    "    df['RSI7'] = ta.rsi(df['Close'], length=7)\n",
    "    df['RSI21'] = ta.rsi(df['Close'], length=21)\n",
    "    df['RSI100'] = ta.rsi(df['Close'], length=100)\n",
    "    df['RSI21_diff'] = df['RSI21'].diff(int(length/2))\n",
    "    timings['rsi'] = time.time() - t0\n",
    "    print(f\"⏱️ rsi: {timings['rsi']:.2f} сек\")\n",
    "\n",
    "    # Объёмные индикаторы\n",
    "    t0 = time.time()\n",
    "    obv_diff = ta.obv(close=df['Close'], volume=df['Volume']).diff()\n",
    "    df['OBV'] = obv_diff / (df['Volume'] + eps)\n",
    "\n",
    "    ad_diff = ta.volume.ad(df['High'], df['Low'], df['Close'], df['Volume']).diff()\n",
    "    df['AD'] = ad_diff / (df['Volume'] + eps)\n",
    "\n",
    "    efi = ta.volume.efi(close=df['Close'], volume=df['Volume'])\n",
    "    df['EFI'] = efi / (df['Volume'].rolling(10).mean() + eps)\n",
    "\n",
    "    df['CMF'] = ta.cmf(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'], length=length)\n",
    "    df['MFI'] = ta.mfi(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'], length=length)\n",
    "    timings['volume_indicators'] = time.time() - t0\n",
    "\n",
    "    # Stochastic RSI\n",
    "    t0 = time.time()\n",
    "    df = calc_stochastic_rsi(df, rsi_period=14, stoch_period=14, smooth_k=3, smooth_d=5)\n",
    "    timings['stoch_rsi'] = time.time() - t0\n",
    "\n",
    "\n",
    "    # Профиль объема\n",
    "    t0 = time.time()\n",
    "    df = add_normalized_volume_profile(df, window=100, lag=3, change_window=5, sma_window=10)\n",
    "    timings['volume_profile'] = time.time() - t0\n",
    "\n",
    "    # Объёмный фильтр\n",
    "    t0 = time.time()\n",
    "    df = add_volume_filter(df, use_ema=True)\n",
    "    timings['volume_filter'] = time.time() - t0\n",
    "\n",
    "    # ATR\n",
    "    t0 = time.time()\n",
    "    df = add_atr_normalized(df, windows=[7, 24, 72])\n",
    "    timings['atr'] = time.time() - t0\n",
    "\n",
    "    # Ишимоку\n",
    "    t0 = time.time()\n",
    "    df = add_normalized_ichimoku(df)\n",
    "    timings['ichimoku'] = time.time() - t0\n",
    "\n",
    "    # Ишимоку htf\n",
    "    t0 = time.time()\n",
    "    df = add_normalized_ichimoku_htf(df)\n",
    "    timings['ichimoku'] = time.time() - t0\n",
    "    print(f\"⏱️ ichimoku: {timings['ichimoku']:.2f} сек\")\n",
    "\n",
    "    # Ишимоку RSI\n",
    "    t0 = time.time()\n",
    "    df = add_normalized_ichimoku_on_rsi(df, rsi_period=9, prefix=\"rsi9_ichimoku\")\n",
    "    df = add_normalized_ichimoku_on_rsi(df, rsi_period=14, prefix=\"rsi14_ichimoku\")\n",
    "    df = add_normalized_ichimoku_on_rsi(df, rsi_period=50, prefix=\"rsi50_ichimoku\")\n",
    "    print(f\"⏱️ Ишимоку RSI: {time.time() - t0:.2f} сек\")\n",
    "\n",
    "    # TRIX + Elder Ray\n",
    "    t0 = time.time()\n",
    "    trix_elder = compute_trix_elder(df)\n",
    "    trix_elder_new_cols = [col for col in trix_elder.columns if col not in df.columns]\n",
    "    df = df.join(trix_elder[trix_elder_new_cols])\n",
    "    timings['trix + elder'] = time.time() - t0\n",
    "\n",
    "    # STC + Fisher + Keltner\n",
    "    t0 = time.time()\n",
    "    new_features = compute_combined_indicators(df)\n",
    "    df[new_features.columns] = new_features\n",
    "    timings['stc + fisher + keltner'] = time.time() - t0\n",
    "\n",
    "    #different MA\n",
    "    t0 = time.time()\n",
    "    # Вычисляем отклонения\n",
    "    deviations = different_MA(df)\n",
    "    # Объединяем с исходным DataFrame (по индексу)\n",
    "    df = pd.concat([df, deviations], axis=1)\n",
    "\n",
    "    deviations = different_EMA(df)\n",
    "    # Объединяем с исходным DataFrame (по индексу)\n",
    "    df = pd.concat([df, deviations], axis=1)\n",
    "    timings['different MA'] = time.time() - t0\n",
    "\n",
    "    #vwap\n",
    "    t0 = time.time()\n",
    "    df = VWAP(df)    \n",
    "    timings['VWAP'] = time.time() - t0\n",
    "\n",
    "    #liquidity_imbalance\n",
    "    t0 = time.time()\n",
    "    df = add_liquidity_imbalance(df)\n",
    "    timings['liquidity_imbalance'] = time.time() - t0\n",
    "\n",
    "\n",
    "    #Liquidity Imbalance Short-Squeeze Score\" (LISS)\n",
    "    t0 = time.time()\n",
    "    df['LISS'] = calculate_LISS(df)\n",
    "    timings['LISS'] = time.time() - t0\n",
    "    print(f\"⏱️ LISS: {timings['LISS']:.2f} сек\")\n",
    "\n",
    "\n",
    "    # Новые фичи\n",
    "    t0 = time.time()\n",
    "    df = add_all_features(df)\n",
    "    print(f\"⏱️ Новые фичи: {time.time() - t0:.2f} сек\")\n",
    "\n",
    "    # Теория четвертей\n",
    "    t0 = time.time()\n",
    "    df = quarter_theory(df)\n",
    "    print(f\"⏱️ Теория четвертей: {time.time() - t0:.2f} сек\")\n",
    "\n",
    "    # Пробой short\n",
    "    t0 = time.time()\n",
    "    df = add_breakdown_flags(df, support_window=50, lookback=int(length / 2))\n",
    "    print(f\"⏱️ Пробой short: {time.time() - t0:.2f} сек\")\n",
    "\n",
    "    # Расчет ML индикаторов\n",
    "    t0 = time.time()\n",
    "    df['wasserstein_100'] = df['Close'].rolling(100).apply(lambda x: wasserstein_distance(x, 100, 50), raw=True)        \n",
    "    df['wasserstein_20'] = df['Close'].rolling(20).apply(lambda x: wasserstein_distance(x, 20, 10), raw=True)       \n",
    "    df['hurst'] = df['Close'].rolling(100).apply(lambda x: hurst_exponent(x, max_lag=100, poly_deg=1), raw=True)            \n",
    "    df['entropy'] = df['Close'].rolling(50).apply(sample_entropy, raw=True)              \n",
    "    df['fft_freq'] = df['Close'].rolling(64).apply(dominant_frequency, raw=True)                \n",
    "    df['nar_res'] = df['Close'].rolling(20).apply(nar_residual, raw=True)\n",
    "    print(f\"⏱️ Расчет ML индикаторов: {time.time() - t0:.2f} сек\")   \n",
    "    \n",
    "    \n",
    "    #Keltner_func\n",
    "    df = Keltner_func(df)\n",
    "\n",
    "    # --- RSI и производные признаки\n",
    "    rsi = compute_rsi(df['Close'], period=14, eps=eps)\n",
    "    df['RSI_14_manual'] = rsi\n",
    "    df['RSI_14_zscore'] = ((rsi - rsi.mean()) / (rsi.std(ddof=0) + eps)).fillna(0)\n",
    "\n",
    "    df['RSI_14_ma'] = rsi.rolling(20).mean()\n",
    "    df['RSI_dist_from_mean'] = rsi - df['RSI_14_ma']\n",
    "\n",
    "    # --- CMF и дивергенции\n",
    "    cmf = compute_cmf(df, length=length, eps=eps)\n",
    "    df['cmf_manual'] = cmf\n",
    "\n",
    "    df['cmf_price_div'] = ((cmf.diff() > 0) & (df['Close'].diff() < 0)).astype(int)\n",
    "    df['rsi_price_div'] = ((rsi.diff() > 0) & (df['Close'].diff() < 0)).astype(int)\n",
    "\n",
    "    # Super trend\n",
    "    t0 = time.time()\n",
    "    df = super_trend(df, period=50, multiplier=1.3)  \n",
    "    df = super_trend(df, period=50, multiplier=5.0)   \n",
    "    df = super_trend(df, period=7, multiplier=1.5)\n",
    "    df = super_trend(df, period=7, multiplier=5.0)\n",
    "    print(f\"⏱️ Расчет Super trend: {time.time() - t0:.2f} сек\")   \n",
    "\n",
    "    # fibo_dinamic\n",
    "    t0 = time.time()\n",
    "    df = fibo_dinamic(df, period=300)\n",
    "    print(f\"⏱️ Расчет fibo_dinamic: {time.time() - t0:.2f} сек\")   \n",
    "    \n",
    "    # Отчет\n",
    "    print(\"⏱️ Время по блокам:\")\n",
    "    for name, duration in timings.items():\n",
    "        print(f\" - {name}: {duration:.2f} сек\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67548e9-5fc3-42b9-ab13-c646005a59ec",
   "metadata": {},
   "source": [
    "### Удаление ненужных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c3f5afc-dd91-4a21-bd58-53671082c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_importance_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Удаляет заранее определённые признаки с низкой важностью, если они присутствуют в датафрейме.\n",
    "    Основано на анализе importance mean ≤ 0 и importance std ≤ 0.001, а также высокой корреляции.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): входной датафрейм.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: датафрейм без указанных признаков.\n",
    "    \"\"\"\n",
    "    features_to_drop = [\n",
    "        # Фичи с нулевой/отрицательной важностью и низкой стабильностью\n",
    "        'lower_low_count', 'AD', 'body_signed', 'bull_inside_bar', 'MFI',\n",
    "        'breakout_now', 'bull_hammer_manual', 'impulse_candle_detected',\n",
    "        'order_block_volume', 'bull_morning_star_manual', 'bull_pin_bar',\n",
    "        'OBV', 'volume_ratio', 'bull_three_white_manual', 'dist_to_fib_500',\n",
    "        'stoch_cross_bull', 'accel_volume', 'accel_volume_fast',\n",
    "        'higher_high_count', 'VP_Change_Norm', 'weighted_direction', 'rsi_low_5', 'divergence_power_20',\n",
    "        'has_divergence_20', 'divergence_power_5', 'has_divergence_5', 'rsi_low_20', 'price_low_20', 'weighted_supertrend',\n",
    "        'price_low_5', 'Close_lag1_z', 'dynamic_direction', 'dynamic_supertrend', 'supertrend_direction',\n",
    "        \n",
    "        # Дополнительные фичи с очень низкой важностью (mean < 0.005)\n",
    "        'fib_touch_count_786', 'CMF', 'stoch_rsi_k', 'sma10',\n",
    "        'bos', 'dist_to_fib_382', 'fib_touch_count_618', 'hybrid_supertrend',\n",
    "        'hybrid_direction', 'supertrend',\n",
    "        \n",
    "        # Удаление корелирующих признаков\n",
    "        'sma20', 'dist_to_fib_618', 'VP_SMA_Norm',\n",
    "        \n",
    "        # Новые фичи для удаления на основе permutation importance и корреляций\n",
    "        'EFI', 'stoch_rsi_d', 'norm_adx',  # Отрицательная/нулевая важность\n",
    "        'RSI7_lag', 'RSI21_lag',    # Сильно коррелируют с другими RSI\n",
    "        'VP_Norm_Lag',            # Высокая корреляция между собой\n",
    "        'optimized_direction',               # Почти идентичен rsi_trend_combo\n",
    "        'ADX_20',                            # Нулевая важность\n",
    "        'atr_14',\n",
    "            'STC',                   # Нулевая Permutation Importance\n",
    "    \n",
    "    'senkou_span_a_norm',    # Отрицательная важность\n",
    "    'Fisher'                # Отрицательная важность\n",
    "    \n",
    "    ]\n",
    "    #'volume_filter','fib_touch_count_236', 'VP_Norm'\n",
    "     \n",
    "    # Удаляем только те фичи, которые есть в датафрейме\n",
    "    return df.drop(columns=[col for col in features_to_drop if col in df.columns], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc741da-9a39-4ffe-92f2-9d2ef422674a",
   "metadata": {},
   "source": [
    "### Оставить только нужные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "33cbaa1d-297b-4589-b2c6-ab97a3c8078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_selected_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Оставляет только выбранные фичи в DataFrame, проверя их наличие и удаляя дубликаты.\"\"\"\n",
    "    top_features = ['target',       \n",
    "    'Data',     \n",
    "    'Volume', 'Open', 'Close', 'High', 'Low',\n",
    "\n",
    "    'senkou_span_a_norm',\n",
    "     'senkou_span_b_norm',\n",
    "     'KeltnerWidth',\n",
    "     'atr_14_norm',\n",
    "     'breakout_in_5',\n",
    "     'rsi50_ichimoku_senkou_a_norm',\n",
    "     'RSI7_1H_norm',\n",
    "     'kijun_sen_norm',\n",
    "     'dist_to_fib_786',\n",
    "     'tenkan_sen_norm_htf',\n",
    "     'linreg',\n",
    "     'TRIX',\n",
    "     'vwma20',\n",
    "     'volume_filter' ]\n",
    "    \n",
    "    # Удаление дубликатов в исходном DF (на случай если они есть)\n",
    "    df = df.loc[:, ~df.columns.duplicated()].copy()\n",
    "    \n",
    "    # Проверка отсутствующих колонок\n",
    "    missing_features = [f for f in top_features if f not in df.columns]\n",
    "    # if missing_features:\n",
    "    #     print(f\"Предупреждение: В DataFrame отсутствуют {len(missing_features)} важных колонок:\") #ЗАКОММЕНТИРОВАЛ ВЫВОД ОШИБОК\n",
    "    #     print(missing_features)\n",
    "    \n",
    "    # Фильтрация: оставляем только существующие колонки из top_features\n",
    "    existing_features = [f for f in top_features if f in df.columns]\n",
    "    \n",
    "    # Удаление колонок, не входящих в топ (если они есть в DF)\n",
    "    extra_features = [f for f in df.columns if f not in top_features]\n",
    "    # if extra_features:\n",
    "    #     print(f\"Удалено {len(extra_features)} лишних колонок, не входящих в топ-фичи\") #ЗАКОММЕНТИРОВАЛ ВЫВОД ОШИБОК\n",
    "    \n",
    "    return df[existing_features].copy()\n",
    "#ЗАКОММЕНТИРОВАЛ ВЫВОД ОШИБОК\n",
    "# Пример использования:\n",
    "# df_processed = keep_selected_features(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282aa30-d7fa-45cb-a8ae-a941a8976ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80853a0-34d6-44f3-ba14-50a3961d2941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d301d-802e-41cc-b3c1-e1e59005460b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python (trading_env)",
   "language": "python",
   "name": "trading_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
